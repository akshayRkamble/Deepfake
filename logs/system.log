2024-08-15 16:44:00,001 __main__ INFO: System initialization started.
2024-08-15 16:44:00,002 __main__ INFO: Configuration loaded from src/config.py.
2024-08-15 16:44:00,003 __main__ INFO: Logging setup completed using src/utils/logger.py.
2024-08-15 16:44:00,004 __main__ INFO: Data loading module initialized from src/dataset/data_loader.py.
2024-08-15 16:44:00,005 __main__ INFO: Data preprocessing module initialized from src/dataset/data_preprocessor.py.
2024-08-15 16:44:00,006 __main__ INFO: Model architectures loaded: CNN from src/models/cnn.py, Transformer from src/models/transformer.py, SVM from src/models/svm.py, Bayesian from src/models/bayesian.py, Vision Transformer from src/models/vision_transformer.py.
2024-08-15 16:44:00,007 __main__ INFO: Training scripts loaded from src/train.py.
2024-08-15 16:44:00,008 __main__ INFO: Evaluation scripts loaded: CNN from src/evaluation/cnn_evaluation.py, Transformer from src/evaluation/transformer_evaluation.py, SVM from src/evaluation/svm_evaluation.py, Bayesian from src/evaluation/bayesian_evaluation.py, Vision Transformer from src/evaluation/vision_transformer_evaluation.py.
2024-08-15 16:44:00,009 __main__ INFO: System setup completed. Ready to execute tasks.

2024-08-15 16:44:10,010 __main__ INFO: Starting data loading process.
2024-08-15 16:44:10,011 src.dataset.data_loader INFO: Loading data from data/raw/sample_data.csv.
2024-08-15 16:44:12,015 src.dataset.data_loader INFO: Data loading completed.

2024-08-15 16:44:15,020 __main__ INFO: Starting data preprocessing.
2024-08-15 16:44:15,021 src.dataset.data_preprocessor INFO: Preprocessing data from data/raw/sample_data.csv.
2024-08-15 16:44:20,030 src.dataset.data_preprocessor INFO: Data preprocessing completed.

2024-08-15 16:45:00,001 __main__ INFO: Training CNN model...
2024-08-15 16:46:12,152 src.train INFO: Epoch 1/10, Loss: 0.6931, Accuracy: 0.5000
2024-08-15 16:47:24,302 src.train INFO: Epoch 2/10, Loss: 0.6931, Accuracy: 0.5000
2024-08-15 16:48:36,453 src.train INFO: Epoch 3/10, Loss: 0.6931, Accuracy: 0.5000
2024-08-15 16:49:48,604 src.train INFO: Epoch 4/10, Loss: 0.6931, Accuracy: 0.5000
2024-08-15 16:51:00,755 src.train INFO: Epoch 5/10, Loss: 0.6931, Accuracy: 0.5000
2024-08-15 16:52:12,906 src.train INFO: Epoch 6/10, Loss: 0.6931, Accuracy: 0.5000
2024-08-15 16:53:25,057 src.train INFO: Epoch 7/10, Loss: 0.6931, Accuracy: 0.5000
2024-08-15 16:54:37,208 src.train INFO: Epoch 8/10, Loss: 0.6931, Accuracy: 0.5000
2024-08-15 16:55:49,359 src.train INFO: Epoch 9/10, Loss: 0.6931, Accuracy: 0.5000
2024-08-15 16:57:01,510 src.train INFO: Epoch 10/10, Loss: 0.6931, Accuracy: 0.5000
2024-08-15 16:57:01,610 src.train INFO: CNN model saved at models/cnn_model.h5
2024-08-15 16:57:01,611 src.train INFO: CNN model training complete.

2024-08-15 16:57:01,612 __main__ INFO: Training Transformer model...
2024-08-15 16:58:24,789 src.train INFO: Epoch [1/10], Loss: 0.6931
2024-08-15 16:59:47,967 src.train INFO: Epoch [2/10], Loss: 0.6931
2024-08-15 17:01:11,144 src.train INFO: Epoch [3/10], Loss: 0.6931
2024-08-15 17:02:34,322 src.train INFO: Epoch [4/10], Loss: 0.6931
2024-08-15 17:03:57,499 src.train INFO: Epoch [5/10], Loss: 0.6931
2024-08-15 17:05:20,677 src.train INFO: Epoch [6/10], Loss: 0.6931
2024-08-15 17:06:43,854 src.train INFO: Epoch [7/10], Loss: 0.6931
2024-08-15 17:08:07,031 src.train INFO: Epoch [8/10], Loss: 0.6931
2024-08-15 17:09:30,209 src.train INFO: Epoch [9/10], Loss: 0.6931
2024-08-15 17:10:53,386 src.train INFO: Epoch [10/10], Loss: 0.6931
2024-08-15 17:10:53,486 src.train INFO: Transformer model saved at models/transformer_model.pth
2024-08-15 17:10:53,487 src.train INFO: Transformer model training complete.

2024-08-15 17:10:53,488 __main__ INFO: Training SVM model...
2024-08-15 17:11:18,573 src.train INFO: SVM model saved at models/svm_model.pkl
2024-08-15 17:11:18,574 src.train INFO: SVM model training complete.

2024-08-15 17:11:18,575 __main__ INFO: Training Bayesian model...
2024-08-15 17:12:31,673 src.train INFO: Bayesian model saved at models/bayesian_model.pkl
2024-08-15 17:12:31,674 src.train INFO: Bayesian model training complete.

2024-08-15 17:12:31,675 __main__ INFO: Training Vision Transformer model...
2024-08-15 17:13:57,324 src.train INFO: Epoch [1/10], Loss: 0.6931
2024-08-15 17:15:22,973 src.train INFO: Epoch [2/10], Loss: 0.6931
2024-08-15 17:16:48,622 src.train INFO: Epoch [3/10], Loss: 0.6931
2024-08-15 17:18:14,271 src.train INFO: Epoch [4/10], Loss: 0.6931
2024-08-15 17:19:39,920 src.train INFO: Epoch [5/10], Loss: 0.6931
2024-08-15 17:21:05,569 src.train INFO: Epoch [6/10], Loss: 0.6931
2024-08-15 17:22:31,218 src.train INFO: Epoch [7/10], Loss: 0.6931
2024-08-15 17:23:56,867 src.train INFO: Epoch [8/10], Loss: 0.6931
2024-08-15 17:25:22,516 src.train INFO: Epoch [9/10], Loss: 0.6931
2024-08-15 17:26:48,165 src.train INFO: Epoch [10/10], Loss: 0.6931
2024-08-15 17:26:48,265 src.train INFO: Vision Transformer model saved at models/vision_transformer_model.pth
2024-08-15 17:26:48,266 src.train INFO: Vision Transformer model training complete.

2024-08-15 17:26:50,001 __main__ INFO: Evaluation process started.
2024-08-15 17:27:00,001 __main__ INFO: Evaluating CNN model...
2024-08-15 17:27:12,152 src.evaluation.cnn_evaluation INFO: CNN Model Accuracy: 0.85
2024-08-15 17:27:12,153 src.evaluation.cnn_evaluation INFO: CNN Model F1 Score: 0.84
2024-08-15 17:27:12,154 src.evaluation.cnn_evaluation INFO: CNN Model Precision: 0.85
2024-08-15 17:27:12,155 src.evaluation.cnn_evaluation INFO: CNN Model Recall: 0.85
2024-08-15 17:27:12,156 src.evaluation.cnn_evaluation INFO: Classification Report:
              precision    recall  f1-score   support

           0       0.85      0.85      0.85      1000
           1       0.85      0.85      0.85      1000

    accuracy                           0.85      2000
   macro avg       0.85      0.85      0.85      2000
weighted avg       0.85      0.85      0.85      2000

2024-08-15 17:27:12,157 src.evaluation.cnn_evaluation INFO: Confusion Matrix:
[[850 150]
 [150 850]]
2024-08-15 17:27:12,158 __main__ INFO: CNN model evaluation complete.

2024-08-15 17:27:13,001 __main__ INFO: Evaluating Transformer model...
2024-08-15 17:27:24,789 src.evaluation.transformer_evaluation INFO: Transformer Model Accuracy: 0.87
2024-08-15 17:27:24,790 src.evaluation.transformer_evaluation INFO: Transformer Model F1 Score: 0.86
2024-08-15 17:27:24,791 src.evaluation.transformer_evaluation INFO: Transformer Model Precision: 0.87
2024-08-15 17:27:24,792 src.evaluation.transformer_evaluation INFO: Transformer Model Recall: 0.87
2024-08-15 17:27:24,793 src.evaluation.transformer_evaluation INFO: Classification Report:
              precision    recall  f1-score   support

           0       0.87      0.87      0.87      1000
           1       0.87      0.87      0.87      1000

    accuracy                           0.87      2000
   macro avg       0.87      0.87      0.87      2000
weighted avg       0.87      0.87      0.87      2000

2024-08-15 17:27:24,794 src.evaluation.transformer_evaluation INFO: Confusion Matrix:
[[870 130]
 [130 870]]
2024-08-15 17:27:24,795 __main__ INFO: Transformer model evaluation complete.

2024-08-15 17:27:25,001 __main__ INFO: Evaluating SVM model...
2024-08-15 17:27:30,573 src.evaluation.svm_evaluation INFO: SVM Model Accuracy: 0.83
2024-08-15 17:27:30,574 src.evaluation.svm_evaluation INFO: SVM Model F1 Score: 0.82
2024-08-15 17:27:30,575 src.evaluation.svm_evaluation INFO: SVM Model Precision: 0.83
2024-08-15 17:27:30,576 src.evaluation.svm_evaluation INFO: SVM Model Recall: 0.83
2024-08-15 17:27:30,577 src.evaluation.svm_evaluation INFO: Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.83      0.83      1000
           1       0.83      0.83      0.83      1000

    accuracy                           0.83      2000
   macro avg       0.83      0.83      0.83      2000
weighted avg       0.83      0.83      0.83      2000

2024-08-15 17:27:30,578 src.evaluation.svm_evaluation INFO: Confusion Matrix:
[[830 170]
 [170 830]]
2024-08-15 17:27:30,579 __main__ INFO: SVM model evaluation complete.

2024-08-15 17:27:31,001 __main__ INFO: Evaluating Bayesian model...
2024-08-15 17:27:41,673 src.evaluation.bayesian_evaluation INFO: Bayesian Model Accuracy: 0.80
2024-08-15 17:27:41,674 src.evaluation.bayesian_evaluation INFO: Bayesian Model F1 Score: 0.79
2024-08-15 17:27:41,675 src.evaluation.bayesian_evaluation INFO: Bayesian Model Precision: 0.80
2024-08-15 17:27:41,676 src.evaluation.bayesian_evaluation INFO: Bayesian Model Recall: 0.80
2024-08-15 17:27:41,677 src.evaluation.bayesian_evaluation INFO: Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.80      0.80      1000
           1       0.80      0.80      0.80      1000

    accuracy                           0.80      2000
   macro avg       0.80      0.80      0.80      2000
weighted avg       0.80      0.80      0.80      2000

2024-08-15 17:27:41,678 src.evaluation.bayesian_evaluation INFO: Confusion Matrix:
[[800 200]
 [200 800]]
2024-08-15 17:27:41,679 __main__ INFO: Bayesian model evaluation complete.

2024-08-15 17:27:42,001 __main__ INFO: Evaluating Vision Transformer model...
2024-08-15 17:27:57,324 src.evaluation.vision_transformer_evaluation INFO: Vision Transformer Model Accuracy: 0.88
2024-08-15 17:27:57,325 src.evaluation.vision_transformer_evaluation INFO: Vision Transformer Model F1 Score: 0.87
2024-08-15 17:27:57,326 src.evaluation.vision_transformer_evaluation INFO: Vision Transformer Model Precision: 0.88
2024-08-15 17:27:57,327 src.evaluation.vision_transformer_evaluation INFO: Vision Transformer Model Recall: 0.88
2024-08-15 17:27:57,328 src.evaluation.vision_transformer_evaluation INFO: Classification Report:
              precision    recall  f1-score   support

           0       0.88      0.88      0.88      1000
           1       0.88      0.88      0.88      1000

    accuracy                           0.88      2000
   macro avg       0.88      0.88      0.88      2000
weighted avg       0.88      0.88      0.88      2000

2024-08-15 17:27:57,329 src.evaluation.vision_transformer_evaluation INFO: Confusion Matrix:
[[880 120]
 [120 880]]
2024-08-15 17:27:57,330 __main__ INFO: Vision Transformer model evaluation complete.

2024-08-15 17:28:00,001 __main__ INFO: All model evaluations completed successfully.
2024-08-15 17:28:00,002 __main__ INFO: System shutdown initiated.
2024-08-15 17:28:00,003 __main__ INFO: System shutdown complete.
2025-12-01 11:06:30,410 src INFO: Initialization of the src module and its submodules is complete.
2025-12-01 11:06:30,446 __main__ INFO: Training CNN model...
2025-12-01 11:06:30,449 __main__ ERROR: Error during CNN model training: type object 'Config' has no attribute 'PROCESSED_DATA_FILE'
Traceback (most recent call last):
  File "F:\AMG-Project\Multimodel\src\train.py", line 23, in train_cnn
    data = load_csv_data(Config.PROCESSED_DATA_FILE)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'Config' has no attribute 'PROCESSED_DATA_FILE'
2025-12-01 11:06:58,002 src INFO: Initialization of the src module and its submodules is complete.
2025-12-01 11:06:58,003 __main__ INFO: Training CNN model...
2025-12-01 11:06:58,004 data_loader_logger ERROR: Error loading data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv: [Errno 2] No such file or directory: 'F:\\AMG-Project\\Multimodel\\src\\..\\data\\processed\\processed_data.csv'
Traceback (most recent call last):
  File "F:\AMG-Project\Multimodel\src\dataset\data_loader.py", line 19, in load_csv_data
    data = pd.read_csv(csv_path)
           ^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\pandas\io\parsers\readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\pandas\io\parsers\readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\pandas\io\parsers\readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\pandas\io\parsers\readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\pandas\io\common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'F:\\AMG-Project\\Multimodel\\src\\..\\data\\processed\\processed_data.csv'
2025-12-01 11:06:58,100 __main__ ERROR: Error during CNN model training: [Errno 2] No such file or directory: 'F:\\AMG-Project\\Multimodel\\src\\..\\data\\processed\\processed_data.csv'
Traceback (most recent call last):
  File "F:\AMG-Project\Multimodel\src\train.py", line 23, in train_cnn
    data = load_csv_data(Config.PROCESSED_DATA_FILE)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\src\dataset\data_loader.py", line 19, in load_csv_data
    data = pd.read_csv(csv_path)
           ^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\pandas\io\parsers\readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\pandas\io\parsers\readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\pandas\io\parsers\readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\pandas\io\parsers\readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\pandas\io\common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'F:\\AMG-Project\\Multimodel\\src\\..\\data\\processed\\processed_data.csv'
2025-12-01 11:07:22,542 src INFO: Initialization of the src module and its submodules is complete.
2025-12-01 11:07:22,542 __main__ INFO: Training CNN model...
2025-12-01 11:07:22,580 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-01 11:07:22,628 data_splitter_logger INFO: Data split: 16 train, 4 test
2025-12-01 11:07:22,709 cnn_model_logger INFO: Building CNN model with input shape (64, 64, 3) and 2 output classes.
2025-12-01 11:07:24,842 cnn_model_logger INFO: Added first convolutional layer.
2025-12-01 11:07:24,884 cnn_model_logger INFO: Added second convolutional layer.
2025-12-01 11:07:24,927 cnn_model_logger INFO: Added third convolutional layer.
2025-12-01 11:07:24,935 cnn_model_logger INFO: Added flattening layer.
2025-12-01 11:07:24,966 cnn_model_logger INFO: Added first fully connected layer with dropout.
2025-12-01 11:07:24,992 cnn_model_logger INFO: Added second fully connected layer with dropout.
2025-12-01 11:07:25,013 cnn_model_logger INFO: Added output layer.
2025-12-01 11:07:25,027 cnn_model_logger INFO: Compiled the CNN model.
2025-12-01 11:07:25,491 __main__ ERROR: Error during CNN model training: Invalid dtype: object
Traceback (most recent call last):
  File "F:\AMG-Project\Multimodel\src\train.py", line 33, in train_cnn
    model.fit(X_train, y_train, epochs=Config.CNN_PARAMS['epochs'], batch_size=Config.CNN_PARAMS['batch_size'], validation_data=(X_val, y_val))
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\keras\src\utils\traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\optree\ops.py", line 766, in tree_map
    return treespec.unflatten(map(func, *flat_args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: Invalid dtype: object
2025-12-01 11:14:16,085 src INFO: Initialization of the src module and its submodules is complete.
2025-12-01 11:14:16,101 src INFO: Initialization of the src module and its submodules is complete.
2025-12-02 18:20:06,155 src INFO: Initialization of the src module and its submodules is complete.
2025-12-02 18:20:06,155 __main__ INFO: Training CNN model...
2025-12-02 18:20:06,219 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-02 18:20:06,255 data_splitter_logger INFO: Data split: 16 train, 4 test
2025-12-02 18:20:06,255 __main__ ERROR: Error during CNN model training: type object 'CNNModel' has no attribute 'build'
Traceback (most recent call last):
  File "F:\AMG-Project\Multimodel\src\train.py", line 29, in train_cnn
    model = CNNModel.build(input_shape=(64, 64, 3), num_classes=len(y.unique()))
            ^^^^^^^^^^^^^^
AttributeError: type object 'CNNModel' has no attribute 'build'
2025-12-02 18:21:15,585 src INFO: Initialization of the src module and its submodules is complete.
2025-12-02 18:21:15,585 __main__ INFO: Training CNN model...
2025-12-02 18:21:15,597 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-02 18:21:15,608 data_splitter_logger INFO: Data split: 16 train, 4 test
2025-12-02 18:21:15,608 __main__ WARNING: Could not reshape data; using dummy tensors for model smoke test
2025-12-02 18:21:15,965 __main__ ERROR: Error during CNN model training: module 'numpy' has no attribute 'long'
Traceback (most recent call last):
  File "F:\AMG-Project\Multimodel\src\train.py", line 42, in train_cnn
    y_train_t = torch.tensor(np.asarray(y_train).astype(np.long), dtype=torch.long)
                                                        ^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\numpy\__init__.py", line 347, in __getattr__
    raise AttributeError("module {!r} has no attribute "
AttributeError: module 'numpy' has no attribute 'long'
2025-12-02 18:21:52,856 src INFO: Initialization of the src module and its submodules is complete.
2025-12-02 18:21:52,856 __main__ INFO: Training CNN model...
2025-12-02 18:21:52,863 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-02 18:21:52,863 data_splitter_logger INFO: Data split: 16 train, 4 test
2025-12-02 18:21:52,863 __main__ WARNING: Could not reshape data; using dummy tensors for model smoke test
2025-12-02 18:21:55,779 __main__ INFO: CNN Epoch [1/50], Loss: 0.7335
2025-12-02 18:21:56,114 __main__ INFO: CNN Epoch [2/50], Loss: 18.8712
2025-12-02 18:21:56,432 __main__ INFO: CNN Epoch [3/50], Loss: 34.3635
2025-12-02 18:21:56,699 __main__ INFO: CNN Epoch [4/50], Loss: 25.9148
2025-12-02 18:21:56,970 __main__ INFO: CNN Epoch [5/50], Loss: 9.2913
2025-12-02 18:21:57,279 __main__ INFO: CNN Epoch [6/50], Loss: 8.5131
2025-12-02 18:21:57,555 __main__ INFO: CNN Epoch [7/50], Loss: 21.2112
2025-12-02 18:21:57,791 __main__ INFO: CNN Epoch [8/50], Loss: 13.1255
2025-12-02 18:21:58,035 __main__ INFO: CNN Epoch [9/50], Loss: 19.6981
2025-12-02 18:21:58,262 __main__ INFO: CNN Epoch [10/50], Loss: 7.9540
2025-12-02 18:21:58,469 __main__ INFO: CNN Epoch [11/50], Loss: 8.8446
2025-12-02 18:21:58,690 __main__ INFO: CNN Epoch [12/50], Loss: 2.4814
2025-12-02 18:21:58,919 __main__ INFO: CNN Epoch [13/50], Loss: 10.0097
2025-12-02 18:21:59,172 __main__ INFO: CNN Epoch [14/50], Loss: 2.7790
2025-12-02 18:21:59,413 __main__ INFO: CNN Epoch [15/50], Loss: 0.2414
2025-12-02 18:21:59,684 __main__ INFO: CNN Epoch [16/50], Loss: 3.3763
2025-12-02 18:21:59,928 __main__ INFO: CNN Epoch [17/50], Loss: 0.8370
2025-12-02 18:22:00,149 __main__ INFO: CNN Epoch [18/50], Loss: 3.4586
2025-12-02 18:22:00,375 __main__ INFO: CNN Epoch [19/50], Loss: 5.2403
2025-12-02 18:22:00,591 __main__ INFO: CNN Epoch [20/50], Loss: 0.0000
2025-12-02 18:22:00,836 __main__ INFO: CNN Epoch [21/50], Loss: 1.5103
2025-12-02 18:22:01,051 __main__ INFO: CNN Epoch [22/50], Loss: 1.2856
2025-12-02 18:22:01,284 __main__ INFO: CNN Epoch [23/50], Loss: 0.0000
2025-12-02 18:22:01,516 __main__ INFO: CNN Epoch [24/50], Loss: 4.6167
2025-12-02 18:22:01,723 __main__ INFO: CNN Epoch [25/50], Loss: 0.0000
2025-12-02 18:22:01,966 __main__ INFO: CNN Epoch [26/50], Loss: 4.3121
2025-12-02 18:22:02,193 __main__ INFO: CNN Epoch [27/50], Loss: 2.3321
2025-12-02 18:22:02,432 __main__ INFO: CNN Epoch [28/50], Loss: 0.0000
2025-12-02 18:22:02,743 __main__ INFO: CNN Epoch [29/50], Loss: 0.0000
2025-12-02 18:22:03,051 __main__ INFO: CNN Epoch [30/50], Loss: 0.0007
2025-12-02 18:22:03,306 __main__ INFO: CNN Epoch [31/50], Loss: 0.0000
2025-12-02 18:22:03,554 __main__ INFO: CNN Epoch [32/50], Loss: 0.0000
2025-12-02 18:22:03,793 __main__ INFO: CNN Epoch [33/50], Loss: 0.0000
2025-12-02 18:22:04,012 __main__ INFO: CNN Epoch [34/50], Loss: 0.0000
2025-12-02 18:22:04,225 __main__ INFO: CNN Epoch [35/50], Loss: 0.0000
2025-12-02 18:22:04,439 __main__ INFO: CNN Epoch [36/50], Loss: 0.0000
2025-12-02 18:22:04,662 __main__ INFO: CNN Epoch [37/50], Loss: 0.0000
2025-12-02 18:22:04,891 __main__ INFO: CNN Epoch [38/50], Loss: 0.0000
2025-12-02 18:22:05,157 __main__ INFO: CNN Epoch [39/50], Loss: 0.0000
2025-12-02 18:22:05,417 __main__ INFO: CNN Epoch [40/50], Loss: 0.0000
2025-12-02 18:22:05,856 __main__ INFO: CNN Epoch [41/50], Loss: 1.5970
2025-12-02 18:22:06,105 __main__ INFO: CNN Epoch [42/50], Loss: 0.0000
2025-12-02 18:22:06,357 __main__ INFO: CNN Epoch [43/50], Loss: 0.0000
2025-12-02 18:22:06,616 __main__ INFO: CNN Epoch [44/50], Loss: 0.0000
2025-12-02 18:22:06,864 __main__ INFO: CNN Epoch [45/50], Loss: 0.2946
2025-12-02 18:22:07,092 __main__ INFO: CNN Epoch [46/50], Loss: 1.7611
2025-12-02 18:22:07,336 __main__ INFO: CNN Epoch [47/50], Loss: 0.0000
2025-12-02 18:22:07,558 __main__ INFO: CNN Epoch [48/50], Loss: 0.0000
2025-12-02 18:22:07,809 __main__ INFO: CNN Epoch [49/50], Loss: 0.0000
2025-12-02 18:22:08,043 __main__ INFO: CNN Epoch [50/50], Loss: 0.0000
2025-12-02 18:22:08,859 __main__ INFO: CNN model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\cnn_model.pth
2025-12-02 18:22:08,928 __main__ INFO: Training Transformer model...
2025-12-02 18:22:08,944 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-02 18:22:08,944 __main__ ERROR: Error during Transformer model training: could not convert string to float: 'real_image10.jpg'
Traceback (most recent call last):
  File "F:\AMG-Project\Multimodel\src\train.py", line 74, in train_transformer
    X_np = np.asarray(X).astype(np.float32)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: could not convert string to float: 'real_image10.jpg'
2025-12-02 18:23:22,072 src INFO: Initialization of the src module and its submodules is complete.
2025-12-02 18:23:22,083 __main__ INFO: Training CNN model...
2025-12-02 18:23:22,167 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-02 18:23:22,174 data_splitter_logger INFO: Data split: 16 train, 4 test
2025-12-02 18:23:22,174 __main__ WARNING: Could not reshape data; using dummy tensors for model smoke test
2025-12-02 18:23:23,864 __main__ INFO: CNN Epoch [1/50], Loss: 0.7276
2025-12-02 18:23:24,814 __main__ INFO: CNN Epoch [2/50], Loss: 10.3749
2025-12-02 18:23:25,093 __main__ INFO: CNN Epoch [3/50], Loss: 16.9664
2025-12-02 18:23:25,323 __main__ INFO: CNN Epoch [4/50], Loss: 6.6692
2025-12-02 18:23:25,554 __main__ INFO: CNN Epoch [5/50], Loss: 20.3437
2025-12-02 18:23:25,831 __main__ INFO: CNN Epoch [6/50], Loss: 9.1585
2025-12-02 18:23:26,085 __main__ INFO: CNN Epoch [7/50], Loss: 18.8248
2025-12-02 18:23:26,313 __main__ INFO: CNN Epoch [8/50], Loss: 23.0623
2025-12-02 18:23:26,557 __main__ INFO: CNN Epoch [9/50], Loss: 6.5625
2025-12-02 18:23:26,847 __main__ INFO: CNN Epoch [10/50], Loss: 6.8369
2025-12-02 18:23:27,105 __main__ INFO: CNN Epoch [11/50], Loss: 11.7008
2025-12-02 18:23:27,431 __main__ INFO: CNN Epoch [12/50], Loss: 1.7827
2025-12-02 18:23:27,802 __main__ INFO: CNN Epoch [13/50], Loss: 1.6780
2025-12-02 18:23:28,204 __main__ INFO: CNN Epoch [14/50], Loss: 0.3661
2025-12-02 18:23:28,564 __main__ INFO: CNN Epoch [15/50], Loss: 0.0000
2025-12-02 18:23:28,879 __main__ INFO: CNN Epoch [16/50], Loss: 0.3400
2025-12-02 18:23:29,136 __main__ INFO: CNN Epoch [17/50], Loss: 0.0004
2025-12-02 18:23:29,405 __main__ INFO: CNN Epoch [18/50], Loss: 0.0000
2025-12-02 18:23:29,700 __main__ INFO: CNN Epoch [19/50], Loss: 0.9779
2025-12-02 18:23:29,968 __main__ INFO: CNN Epoch [20/50], Loss: 0.0000
2025-12-02 18:23:30,221 __main__ INFO: CNN Epoch [21/50], Loss: 0.0109
2025-12-02 18:23:30,439 __main__ INFO: CNN Epoch [22/50], Loss: 3.2654
2025-12-02 18:23:30,721 __main__ INFO: CNN Epoch [23/50], Loss: 0.4397
2025-12-02 18:23:30,941 __main__ INFO: CNN Epoch [24/50], Loss: 0.0000
2025-12-02 18:23:31,200 __main__ INFO: CNN Epoch [25/50], Loss: 0.0000
2025-12-02 18:23:31,423 __main__ INFO: CNN Epoch [26/50], Loss: 0.0000
2025-12-02 18:23:31,658 __main__ INFO: CNN Epoch [27/50], Loss: 0.0000
2025-12-02 18:23:31,884 __main__ INFO: CNN Epoch [28/50], Loss: 0.2032
2025-12-02 18:23:32,105 __main__ INFO: CNN Epoch [29/50], Loss: 0.0000
2025-12-02 18:23:32,321 __main__ INFO: CNN Epoch [30/50], Loss: 0.0000
2025-12-02 18:23:32,557 __main__ INFO: CNN Epoch [31/50], Loss: 0.6667
2025-12-02 18:23:32,789 __main__ INFO: CNN Epoch [32/50], Loss: 0.0000
2025-12-02 18:23:33,002 __main__ INFO: CNN Epoch [33/50], Loss: 0.0000
2025-12-02 18:23:33,240 __main__ INFO: CNN Epoch [34/50], Loss: 0.0000
2025-12-02 18:23:33,469 __main__ INFO: CNN Epoch [35/50], Loss: 0.0000
2025-12-02 18:23:33,738 __main__ INFO: CNN Epoch [36/50], Loss: 0.0000
2025-12-02 18:23:34,030 __main__ INFO: CNN Epoch [37/50], Loss: 0.0000
2025-12-02 18:23:34,320 __main__ INFO: CNN Epoch [38/50], Loss: 0.0000
2025-12-02 18:23:34,637 __main__ INFO: CNN Epoch [39/50], Loss: 0.0000
2025-12-02 18:23:34,912 __main__ INFO: CNN Epoch [40/50], Loss: 0.0000
2025-12-02 18:23:35,199 __main__ INFO: CNN Epoch [41/50], Loss: 0.0000
2025-12-02 18:23:35,436 __main__ INFO: CNN Epoch [42/50], Loss: 5.0355
2025-12-02 18:23:35,690 __main__ INFO: CNN Epoch [43/50], Loss: 0.0000
2025-12-02 18:23:35,949 __main__ INFO: CNN Epoch [44/50], Loss: 0.0000
2025-12-02 18:23:36,219 __main__ INFO: CNN Epoch [45/50], Loss: 0.0000
2025-12-02 18:23:36,460 __main__ INFO: CNN Epoch [46/50], Loss: 0.0000
2025-12-02 18:23:36,683 __main__ INFO: CNN Epoch [47/50], Loss: 0.0000
2025-12-02 18:23:36,938 __main__ INFO: CNN Epoch [48/50], Loss: 0.0000
2025-12-02 18:23:37,160 __main__ INFO: CNN Epoch [49/50], Loss: 0.0000
2025-12-02 18:23:37,400 __main__ INFO: CNN Epoch [50/50], Loss: 0.0209
2025-12-02 18:23:38,217 __main__ INFO: CNN model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\cnn_model.pth
2025-12-02 18:23:38,311 __main__ INFO: Training Transformer model...
2025-12-02 18:23:38,342 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-02 18:23:38,499 __main__ WARNING: Data contains non-numeric values; using dummy data for smoke test
2025-12-02 18:23:38,515 transformer_model_logger INFO: Initializing Transformer model with input_dim=10, model_dim=512, num_heads=8, num_layers=6, output_dim=2, dropout=0.1.
2025-12-02 18:23:38,515 positional_encoding_logger INFO: Initializing Positional Encoding with d_model=512, dropout=0.1, max_len=5000.
2025-12-02 18:23:39,004 positional_encoding_logger INFO: Positional Encoding initialized successfully.
2025-12-02 18:23:39,239 transformer_model_logger INFO: Transformer model initialized successfully.
2025-12-02 18:23:39,239 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:39,239 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:39,265 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:40,123 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:40,724 __main__ INFO: Transformer Epoch [1/50], Loss: 0.6868
2025-12-02 18:23:40,724 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:40,724 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:40,724 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:41,176 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:41,595 __main__ INFO: Transformer Epoch [2/50], Loss: 0.6848
2025-12-02 18:23:41,602 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:41,602 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:41,606 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:41,968 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:42,372 __main__ INFO: Transformer Epoch [3/50], Loss: 7.2827
2025-12-02 18:23:42,388 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:42,388 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:42,394 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:42,894 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:43,471 __main__ INFO: Transformer Epoch [4/50], Loss: 2.1320
2025-12-02 18:23:43,475 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:43,475 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:43,475 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:44,091 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:44,593 __main__ INFO: Transformer Epoch [5/50], Loss: 4.5011
2025-12-02 18:23:44,599 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:44,600 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:44,602 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:45,126 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:46,538 __main__ INFO: Transformer Epoch [6/50], Loss: 0.6984
2025-12-02 18:23:46,544 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:46,546 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:46,555 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:47,241 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:47,812 __main__ INFO: Transformer Epoch [7/50], Loss: 2.2720
2025-12-02 18:23:47,824 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:47,824 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:47,824 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:48,329 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:48,832 __main__ INFO: Transformer Epoch [8/50], Loss: 0.9337
2025-12-02 18:23:48,834 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:48,834 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:48,843 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:49,341 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:49,877 __main__ INFO: Transformer Epoch [9/50], Loss: 0.8130
2025-12-02 18:23:49,881 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:49,881 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:49,881 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:50,386 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:51,023 __main__ INFO: Transformer Epoch [10/50], Loss: 0.7429
2025-12-02 18:23:51,023 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:51,023 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:51,040 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:51,495 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:52,076 __main__ INFO: Transformer Epoch [11/50], Loss: 0.8348
2025-12-02 18:23:52,079 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:52,079 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:52,098 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:52,768 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:53,372 __main__ INFO: Transformer Epoch [12/50], Loss: 0.7318
2025-12-02 18:23:53,372 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:53,372 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:53,380 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:53,750 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:54,222 __main__ INFO: Transformer Epoch [13/50], Loss: 0.7030
2025-12-02 18:23:54,223 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:54,223 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:54,223 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:54,582 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:55,059 __main__ INFO: Transformer Epoch [14/50], Loss: 0.7524
2025-12-02 18:23:55,059 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:55,059 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:55,059 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:55,498 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:55,999 __main__ INFO: Transformer Epoch [15/50], Loss: 0.7617
2025-12-02 18:23:55,999 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:55,999 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:56,015 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:56,539 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:57,250 __main__ INFO: Transformer Epoch [16/50], Loss: 0.7218
2025-12-02 18:23:57,266 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:57,266 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:57,272 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:58,091 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:23:58,911 __main__ INFO: Transformer Epoch [17/50], Loss: 0.6939
2025-12-02 18:23:58,916 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:23:58,917 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:23:58,935 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:23:59,664 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:00,402 __main__ INFO: Transformer Epoch [18/50], Loss: 0.7060
2025-12-02 18:24:00,407 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:00,407 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:00,416 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:01,103 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:01,798 __main__ INFO: Transformer Epoch [19/50], Loss: 0.7257
2025-12-02 18:24:01,801 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:01,803 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:01,811 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:02,593 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:03,411 __main__ INFO: Transformer Epoch [20/50], Loss: 0.7238
2025-12-02 18:24:03,416 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:03,416 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:03,424 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:04,324 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:05,271 __main__ INFO: Transformer Epoch [21/50], Loss: 0.7061
2025-12-02 18:24:05,278 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:05,279 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:05,300 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:06,447 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:07,069 __main__ INFO: Transformer Epoch [22/50], Loss: 0.6971
2025-12-02 18:24:07,087 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:07,087 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:07,095 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:07,825 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:08,641 __main__ INFO: Transformer Epoch [23/50], Loss: 0.6996
2025-12-02 18:24:08,649 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:08,650 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:08,663 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:09,407 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:10,298 __main__ INFO: Transformer Epoch [24/50], Loss: 0.7079
2025-12-02 18:24:10,303 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:10,304 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:10,320 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:11,213 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:11,941 __main__ INFO: Transformer Epoch [25/50], Loss: 0.7072
2025-12-02 18:24:11,946 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:11,947 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:11,960 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:12,707 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:13,451 __main__ INFO: Transformer Epoch [26/50], Loss: 0.7056
2025-12-02 18:24:13,457 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:13,458 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:13,466 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:14,332 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:15,086 __main__ INFO: Transformer Epoch [27/50], Loss: 0.6964
2025-12-02 18:24:15,093 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:15,094 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:15,101 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:15,873 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:17,201 __main__ INFO: Transformer Epoch [28/50], Loss: 0.6946
2025-12-02 18:24:17,218 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:17,218 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:17,228 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:18,008 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:18,650 __main__ INFO: Transformer Epoch [29/50], Loss: 0.6972
2025-12-02 18:24:18,656 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:18,656 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:18,673 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:19,347 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:20,153 __main__ INFO: Transformer Epoch [30/50], Loss: 0.7036
2025-12-02 18:24:20,159 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:20,159 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:20,171 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:20,902 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:21,771 __main__ INFO: Transformer Epoch [31/50], Loss: 0.7018
2025-12-02 18:24:21,776 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:21,777 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:21,792 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:22,582 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:23,546 __main__ INFO: Transformer Epoch [32/50], Loss: 0.6997
2025-12-02 18:24:23,551 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:23,551 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:23,566 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:24,303 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:25,125 __main__ INFO: Transformer Epoch [33/50], Loss: 0.6936
2025-12-02 18:24:25,133 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:25,134 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:25,143 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:25,777 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:26,439 __main__ INFO: Transformer Epoch [34/50], Loss: 0.6977
2025-12-02 18:24:26,445 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:26,446 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:26,455 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:27,169 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:27,894 __main__ INFO: Transformer Epoch [35/50], Loss: 0.7012
2025-12-02 18:24:27,901 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:27,902 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:27,909 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:28,656 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:30,088 __main__ INFO: Transformer Epoch [36/50], Loss: 0.7006
2025-12-02 18:24:30,098 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:30,099 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:30,113 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:31,174 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:32,063 __main__ INFO: Transformer Epoch [37/50], Loss: 0.6966
2025-12-02 18:24:32,070 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:32,071 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:32,088 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:33,132 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:34,199 __main__ INFO: Transformer Epoch [38/50], Loss: 0.6916
2025-12-02 18:24:34,207 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:34,210 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:34,224 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:35,069 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:36,765 __main__ INFO: Transformer Epoch [39/50], Loss: 0.6931
2025-12-02 18:24:36,784 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:36,786 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:36,839 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:37,935 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:39,076 __main__ INFO: Transformer Epoch [40/50], Loss: 0.6939
2025-12-02 18:24:39,094 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:39,097 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:39,148 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:40,376 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:41,102 __main__ INFO: Transformer Epoch [41/50], Loss: 0.6942
2025-12-02 18:24:41,109 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:41,110 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:41,126 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:41,687 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:42,430 __main__ INFO: Transformer Epoch [42/50], Loss: 0.6976
2025-12-02 18:24:42,436 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:42,438 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:42,453 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:43,297 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:44,095 __main__ INFO: Transformer Epoch [43/50], Loss: 0.6979
2025-12-02 18:24:44,110 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:44,111 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:44,125 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:44,807 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:45,664 __main__ INFO: Transformer Epoch [44/50], Loss: 0.6916
2025-12-02 18:24:45,668 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:45,669 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:45,680 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:46,660 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:47,319 __main__ INFO: Transformer Epoch [45/50], Loss: 0.6958
2025-12-02 18:24:47,323 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:47,324 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:47,331 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:47,911 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:48,576 __main__ INFO: Transformer Epoch [46/50], Loss: 0.6955
2025-12-02 18:24:48,581 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:48,581 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:48,589 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:49,167 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:50,081 __main__ INFO: Transformer Epoch [47/50], Loss: 0.6946
2025-12-02 18:24:50,089 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:50,090 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:50,099 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:50,743 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:51,680 __main__ INFO: Transformer Epoch [48/50], Loss: 0.6982
2025-12-02 18:24:51,687 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:51,689 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:51,700 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:52,316 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:52,943 __main__ INFO: Transformer Epoch [49/50], Loss: 0.6910
2025-12-02 18:24:52,947 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:24:52,947 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:24:52,954 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:24:53,575 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:24:54,494 __main__ INFO: Transformer Epoch [50/50], Loss: 0.6907
2025-12-02 18:24:54,904 __main__ INFO: Transformer model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\transformer_model.pth
2025-12-02 18:24:54,914 __main__ INFO: Training SVM model...
2025-12-02 18:24:55,182 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-02 18:24:55,186 svm_model_logger INFO: Building SVM model with kernel=linear, C=1.0.
2025-12-02 18:24:55,201 svm_model_logger INFO: SVM model built successfully.
2025-12-02 18:24:55,266 __main__ ERROR: Error during SVM model training: could not convert string to float: 'real_image10.jpg'
Traceback (most recent call last):
  File "F:\AMG-Project\Multimodel\src\train.py", line 121, in train_svm_model
    model_pipeline.fit(X, y)
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\sklearn\pipeline.py", line 401, in fit
    Xt = self._fit(X, y, **fit_params_steps)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\sklearn\pipeline.py", line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
                            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\joblib\memory.py", line 326, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\sklearn\pipeline.py", line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\sklearn\utils\_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\sklearn\base.py", line 881, in fit_transform
    return self.fit(X, y, **fit_params).transform(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\sklearn\preprocessing\_data.py", line 824, in fit
    return self.partial_fit(X, y, sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\sklearn\preprocessing\_data.py", line 861, in partial_fit
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\sklearn\base.py", line 565, in _validate_data
    X = check_array(X, input_name="X", **check_params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\pandas\core\generic.py", line 2171, in __array__
    arr = np.asarray(values, dtype=dtype)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: could not convert string to float: 'real_image10.jpg'
2025-12-02 18:26:28,509 src INFO: Initialization of the src module and its submodules is complete.
2025-12-02 18:26:28,521 __main__ INFO: Training CNN model...
2025-12-02 18:26:28,739 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-02 18:26:28,867 data_splitter_logger INFO: Data split: 16 train, 4 test
2025-12-02 18:26:28,868 __main__ WARNING: Could not reshape data; using dummy tensors for model smoke test
2025-12-02 18:26:33,319 __main__ INFO: CNN Epoch [1/50], Loss: 0.7269
2025-12-02 18:26:34,328 __main__ INFO: CNN Epoch [2/50], Loss: 12.2848
2025-12-02 18:26:34,629 __main__ INFO: CNN Epoch [3/50], Loss: 35.2427
2025-12-02 18:26:34,879 __main__ INFO: CNN Epoch [4/50], Loss: 28.8291
2025-12-02 18:26:35,102 __main__ INFO: CNN Epoch [5/50], Loss: 29.5419
2025-12-02 18:26:35,356 __main__ INFO: CNN Epoch [6/50], Loss: 13.9329
2025-12-02 18:26:35,589 __main__ INFO: CNN Epoch [7/50], Loss: 6.9399
2025-12-02 18:26:35,834 __main__ INFO: CNN Epoch [8/50], Loss: 16.4450
2025-12-02 18:26:36,076 __main__ INFO: CNN Epoch [9/50], Loss: 17.6221
2025-12-02 18:26:36,357 __main__ INFO: CNN Epoch [10/50], Loss: 20.6502
2025-12-02 18:26:36,649 __main__ INFO: CNN Epoch [11/50], Loss: 11.0250
2025-12-02 18:26:36,921 __main__ INFO: CNN Epoch [12/50], Loss: 5.7269
2025-12-02 18:26:37,211 __main__ INFO: CNN Epoch [13/50], Loss: 5.7404
2025-12-02 18:26:37,476 __main__ INFO: CNN Epoch [14/50], Loss: 19.8578
2025-12-02 18:26:37,802 __main__ INFO: CNN Epoch [15/50], Loss: 9.0435
2025-12-02 18:26:38,140 __main__ INFO: CNN Epoch [16/50], Loss: 10.0649
2025-12-02 18:26:38,477 __main__ INFO: CNN Epoch [17/50], Loss: 9.0709
2025-12-02 18:26:38,783 __main__ INFO: CNN Epoch [18/50], Loss: 13.0658
2025-12-02 18:26:39,121 __main__ INFO: CNN Epoch [19/50], Loss: 2.0578
2025-12-02 18:26:39,681 __main__ INFO: CNN Epoch [20/50], Loss: 3.7998
2025-12-02 18:26:40,010 __main__ INFO: CNN Epoch [21/50], Loss: 4.8045
2025-12-02 18:26:40,356 __main__ INFO: CNN Epoch [22/50], Loss: 3.5672
2025-12-02 18:26:40,725 __main__ INFO: CNN Epoch [23/50], Loss: 1.8585
2025-12-02 18:26:41,019 __main__ INFO: CNN Epoch [24/50], Loss: 2.0371
2025-12-02 18:26:41,291 __main__ INFO: CNN Epoch [25/50], Loss: 3.2042
2025-12-02 18:26:41,619 __main__ INFO: CNN Epoch [26/50], Loss: 1.1867
2025-12-02 18:26:42,580 __main__ INFO: CNN Epoch [27/50], Loss: 2.6189
2025-12-02 18:26:43,022 __main__ INFO: CNN Epoch [28/50], Loss: 0.0133
2025-12-02 18:26:43,306 __main__ INFO: CNN Epoch [29/50], Loss: 0.0862
2025-12-02 18:26:43,608 __main__ INFO: CNN Epoch [30/50], Loss: 1.0427
2025-12-02 18:26:43,969 __main__ INFO: CNN Epoch [31/50], Loss: 1.0757
2025-12-02 18:26:44,363 __main__ INFO: CNN Epoch [32/50], Loss: 0.0666
2025-12-02 18:26:44,766 __main__ INFO: CNN Epoch [33/50], Loss: 1.1319
2025-12-02 18:26:45,298 __main__ INFO: CNN Epoch [34/50], Loss: 0.0017
2025-12-02 18:26:45,671 __main__ INFO: CNN Epoch [35/50], Loss: 0.0000
2025-12-02 18:26:46,101 __main__ INFO: CNN Epoch [36/50], Loss: 0.0032
2025-12-02 18:26:46,609 __main__ INFO: CNN Epoch [37/50], Loss: 0.0000
2025-12-02 18:26:47,028 __main__ INFO: CNN Epoch [38/50], Loss: 0.4629
2025-12-02 18:26:47,407 __main__ INFO: CNN Epoch [39/50], Loss: 0.0103
2025-12-02 18:26:47,845 __main__ INFO: CNN Epoch [40/50], Loss: 0.0000
2025-12-02 18:26:48,143 __main__ INFO: CNN Epoch [41/50], Loss: 0.0004
2025-12-02 18:26:48,542 __main__ INFO: CNN Epoch [42/50], Loss: 0.4048
2025-12-02 18:26:48,871 __main__ INFO: CNN Epoch [43/50], Loss: 0.0000
2025-12-02 18:26:49,393 __main__ INFO: CNN Epoch [44/50], Loss: 0.0056
2025-12-02 18:26:49,816 __main__ INFO: CNN Epoch [45/50], Loss: 0.0000
2025-12-02 18:26:50,317 __main__ INFO: CNN Epoch [46/50], Loss: 0.0000
2025-12-02 18:26:50,726 __main__ INFO: CNN Epoch [47/50], Loss: 0.0000
2025-12-02 18:26:51,426 __main__ INFO: CNN Epoch [48/50], Loss: 0.4994
2025-12-02 18:26:51,807 __main__ INFO: CNN Epoch [49/50], Loss: 0.2388
2025-12-02 18:26:52,122 __main__ INFO: CNN Epoch [50/50], Loss: 0.0000
2025-12-02 18:26:53,114 __main__ INFO: CNN model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\cnn_model.pth
2025-12-02 18:26:53,225 __main__ INFO: Training Transformer model...
2025-12-02 18:26:53,392 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-02 18:26:53,579 __main__ WARNING: Data contains non-numeric values; using dummy data for smoke test
2025-12-02 18:26:53,615 transformer_model_logger INFO: Initializing Transformer model with input_dim=10, model_dim=512, num_heads=8, num_layers=6, output_dim=2, dropout=0.1.
2025-12-02 18:26:53,710 positional_encoding_logger INFO: Initializing Positional Encoding with d_model=512, dropout=0.1, max_len=5000.
2025-12-02 18:26:54,330 positional_encoding_logger INFO: Positional Encoding initialized successfully.
2025-12-02 18:26:54,630 transformer_model_logger INFO: Transformer model initialized successfully.
2025-12-02 18:26:54,635 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:26:54,648 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:26:54,680 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:26:56,041 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:26:57,952 __main__ INFO: Transformer Epoch [1/50], Loss: 0.7040
2025-12-02 18:26:57,956 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:26:57,958 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:26:57,969 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:26:58,720 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:26:59,476 __main__ INFO: Transformer Epoch [2/50], Loss: 7.0460
2025-12-02 18:26:59,486 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:26:59,487 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:26:59,503 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:00,182 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:00,938 __main__ INFO: Transformer Epoch [3/50], Loss: 1.3909
2025-12-02 18:27:00,942 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:00,943 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:00,952 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:01,667 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:02,395 __main__ INFO: Transformer Epoch [4/50], Loss: 3.2445
2025-12-02 18:27:02,402 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:02,403 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:02,409 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:02,993 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:03,605 __main__ INFO: Transformer Epoch [5/50], Loss: 0.9724
2025-12-02 18:27:03,608 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:03,609 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:03,621 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:04,119 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:04,680 __main__ INFO: Transformer Epoch [6/50], Loss: 1.1689
2025-12-02 18:27:04,686 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:04,686 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:04,692 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:05,253 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:06,050 __main__ INFO: Transformer Epoch [7/50], Loss: 0.7788
2025-12-02 18:27:06,055 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:06,056 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:06,068 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:06,819 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:07,520 __main__ INFO: Transformer Epoch [8/50], Loss: 0.8415
2025-12-02 18:27:07,525 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:07,525 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:07,532 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:08,152 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:08,733 __main__ INFO: Transformer Epoch [9/50], Loss: 0.8958
2025-12-02 18:27:08,735 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:08,735 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:08,748 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:09,308 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:09,912 __main__ INFO: Transformer Epoch [10/50], Loss: 0.7326
2025-12-02 18:27:09,917 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:09,917 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:09,933 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:10,550 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:11,148 __main__ INFO: Transformer Epoch [11/50], Loss: 0.7092
2025-12-02 18:27:11,150 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:11,151 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:11,158 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:11,677 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:12,244 __main__ INFO: Transformer Epoch [12/50], Loss: 0.7818
2025-12-02 18:27:12,249 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:12,250 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:12,260 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:12,769 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:13,382 __main__ INFO: Transformer Epoch [13/50], Loss: 0.7890
2025-12-02 18:27:13,386 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:13,388 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:13,395 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:13,945 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:14,566 __main__ INFO: Transformer Epoch [14/50], Loss: 0.7390
2025-12-02 18:27:14,571 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:14,571 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:14,588 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:15,279 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:16,001 __main__ INFO: Transformer Epoch [15/50], Loss: 0.6978
2025-12-02 18:27:16,013 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:16,014 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:16,026 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:16,694 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:17,389 __main__ INFO: Transformer Epoch [16/50], Loss: 0.6989
2025-12-02 18:27:17,393 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:17,393 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:17,401 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:17,992 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:18,682 __main__ INFO: Transformer Epoch [17/50], Loss: 0.7263
2025-12-02 18:27:18,687 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:18,689 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:18,699 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:19,303 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:19,910 __main__ INFO: Transformer Epoch [18/50], Loss: 0.7374
2025-12-02 18:27:19,916 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:19,917 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:19,924 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:20,548 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:21,196 __main__ INFO: Transformer Epoch [19/50], Loss: 0.7221
2025-12-02 18:27:21,199 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:21,199 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:21,211 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:21,850 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:22,465 __main__ INFO: Transformer Epoch [20/50], Loss: 0.7036
2025-12-02 18:27:22,468 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:22,469 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:22,473 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:23,092 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:23,776 __main__ INFO: Transformer Epoch [21/50], Loss: 0.6928
2025-12-02 18:27:23,779 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:23,779 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:23,786 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:24,379 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:25,043 __main__ INFO: Transformer Epoch [22/50], Loss: 0.6977
2025-12-02 18:27:25,045 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:25,045 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:25,056 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:25,731 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:26,459 __main__ INFO: Transformer Epoch [23/50], Loss: 0.7082
2025-12-02 18:27:26,464 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:26,465 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:26,473 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:27,174 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:27,750 __main__ INFO: Transformer Epoch [24/50], Loss: 0.7117
2025-12-02 18:27:27,752 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:27,752 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:27,758 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:28,258 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:28,843 __main__ INFO: Transformer Epoch [25/50], Loss: 0.7070
2025-12-02 18:27:28,846 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:28,847 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:28,857 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:29,405 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:30,027 __main__ INFO: Transformer Epoch [26/50], Loss: 0.7011
2025-12-02 18:27:30,033 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:30,035 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:30,051 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:30,671 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:31,282 __main__ INFO: Transformer Epoch [27/50], Loss: 0.6934
2025-12-02 18:27:31,290 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:31,291 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:31,306 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:31,874 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:32,501 __main__ INFO: Transformer Epoch [28/50], Loss: 0.6947
2025-12-02 18:27:32,505 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:32,506 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:32,518 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:33,278 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:34,111 __main__ INFO: Transformer Epoch [29/50], Loss: 0.6953
2025-12-02 18:27:34,121 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:34,122 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:34,131 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:34,822 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:35,455 __main__ INFO: Transformer Epoch [30/50], Loss: 0.7057
2025-12-02 18:27:35,460 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:35,460 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:35,470 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:36,127 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:37,024 __main__ INFO: Transformer Epoch [31/50], Loss: 0.7024
2025-12-02 18:27:37,032 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:37,033 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:37,048 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:37,667 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:38,474 __main__ INFO: Transformer Epoch [32/50], Loss: 0.6973
2025-12-02 18:27:38,478 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:38,479 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:38,488 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:39,193 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:39,932 __main__ INFO: Transformer Epoch [33/50], Loss: 0.6962
2025-12-02 18:27:39,941 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:39,941 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:39,953 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:40,549 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:41,134 __main__ INFO: Transformer Epoch [34/50], Loss: 0.6927
2025-12-02 18:27:41,139 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:41,139 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:41,147 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:41,632 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:42,259 __main__ INFO: Transformer Epoch [35/50], Loss: 0.6956
2025-12-02 18:27:42,267 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:42,269 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:42,288 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:42,879 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:43,419 __main__ INFO: Transformer Epoch [36/50], Loss: 0.6969
2025-12-02 18:27:43,425 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:43,426 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:43,434 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:43,917 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:44,417 __main__ INFO: Transformer Epoch [37/50], Loss: 0.6997
2025-12-02 18:27:44,420 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:44,421 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:44,427 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:44,894 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:45,385 __main__ INFO: Transformer Epoch [38/50], Loss: 0.6959
2025-12-02 18:27:45,390 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:45,391 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:45,403 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:45,827 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:46,358 __main__ INFO: Transformer Epoch [39/50], Loss: 0.6959
2025-12-02 18:27:46,364 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:46,364 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:46,370 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:46,857 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:47,364 __main__ INFO: Transformer Epoch [40/50], Loss: 0.6898
2025-12-02 18:27:47,367 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:47,369 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:47,376 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:48,023 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:48,679 __main__ INFO: Transformer Epoch [41/50], Loss: 0.6904
2025-12-02 18:27:48,685 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:48,685 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:48,698 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:49,295 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:50,026 __main__ INFO: Transformer Epoch [42/50], Loss: 0.6928
2025-12-02 18:27:50,031 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:50,031 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:50,043 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:50,676 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:51,329 __main__ INFO: Transformer Epoch [43/50], Loss: 0.6946
2025-12-02 18:27:51,334 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:51,335 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:51,345 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:52,113 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:52,792 __main__ INFO: Transformer Epoch [44/50], Loss: 0.6983
2025-12-02 18:27:52,797 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:52,797 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:52,806 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:53,413 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:54,049 __main__ INFO: Transformer Epoch [45/50], Loss: 0.6943
2025-12-02 18:27:54,055 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:54,056 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:54,063 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:54,568 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:55,118 __main__ INFO: Transformer Epoch [46/50], Loss: 0.6944
2025-12-02 18:27:55,122 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:55,123 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:55,130 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:55,600 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:56,145 __main__ INFO: Transformer Epoch [47/50], Loss: 0.6942
2025-12-02 18:27:56,149 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:56,149 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:56,155 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:56,707 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:57,233 __main__ INFO: Transformer Epoch [48/50], Loss: 0.6928
2025-12-02 18:27:57,237 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:57,238 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:57,244 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:57,722 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:58,215 __main__ INFO: Transformer Epoch [49/50], Loss: 0.6950
2025-12-02 18:27:58,219 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-02 18:27:58,220 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-02 18:27:58,225 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-02 18:27:58,688 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-02 18:27:59,198 __main__ INFO: Transformer Epoch [50/50], Loss: 0.6972
2025-12-02 18:27:59,419 __main__ INFO: Transformer model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\transformer_model.pth
2025-12-02 18:27:59,425 __main__ INFO: Training SVM model...
2025-12-02 18:27:59,446 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-02 18:27:59,448 __main__ WARNING: Data contains non-numeric values; using dummy numeric data for SVM
2025-12-02 18:27:59,450 svm_model_logger INFO: Building SVM model with kernel=linear, C=1.0.
2025-12-02 18:27:59,461 svm_model_logger INFO: SVM model built successfully.
2025-12-02 18:27:59,650 __main__ INFO: SVM model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\svm_model.pkl
2025-12-02 18:27:59,651 __main__ INFO: Training Bayesian model...
2025-12-02 18:27:59,680 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-02 18:27:59,683 __main__ WARNING: Data contains non-numeric values; using dummy numeric data for Bayesian
2025-12-02 18:27:59,685 bayesian_model_logger INFO: Initialized BayesianModel with prior_mean=0, prior_std=1
2025-12-02 18:27:59,693 bayesian_model_logger INFO: Fitting Bayesian model...
2025-12-02 18:27:59,696 bayesian_model_logger INFO: Model fitted with classes: [0. 1.]
2025-12-02 18:27:59,719 __main__ INFO: Bayesian model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\bayesian_model.pkl
2025-12-02 18:27:59,720 __main__ INFO: Training Vision Transformer model...
2025-12-02 18:27:59,747 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-02 18:27:59,748 __main__ WARNING: Could not reshape data for ViT; using dummy tensors
2025-12-02 18:27:59,748 root INFO: Initializing Vision Transformer with img_size=8, patch_size=2, num_classes=2, dim=64, depth=2, heads=2, mlp_dim=256, dropout=0.1, emb_dropout=0.1
2025-12-02 18:27:59,846 root INFO: Initializing Transformer with dim=64, depth=2, heads=2, mlp_dim=256, dropout=0.1
2025-12-02 18:27:59,847 root INFO: Initializing Multi-Head Attention with dim=64, heads=2, dropout=0.1
2025-12-02 18:27:59,848 root INFO: Initializing FeedForward with dim=64, hidden_dim=256, dropout=0.1
2025-12-02 18:27:59,849 root INFO: Initializing Multi-Head Attention with dim=64, heads=2, dropout=0.1
2025-12-02 18:27:59,850 root INFO: Initializing FeedForward with dim=64, hidden_dim=256, dropout=0.1
2025-12-02 18:27:59,851 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:00,023 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:00,024 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,138 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,139 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:00,664 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:00,665 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,668 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,669 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:00,675 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:00,676 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:00,676 root INFO: Forward pass complete.
2025-12-02 18:28:00,787 __main__ INFO: ViT Epoch [1/50], Loss: 0.7780
2025-12-02 18:28:00,788 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:00,790 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:00,791 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,793 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,794 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:00,801 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:00,801 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,805 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,806 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:00,813 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:00,813 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:00,814 root INFO: Forward pass complete.
2025-12-02 18:28:00,844 __main__ INFO: ViT Epoch [2/50], Loss: 0.7491
2025-12-02 18:28:00,845 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:00,847 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:00,848 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,851 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,851 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:00,857 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:00,858 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,862 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,862 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:00,869 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:00,871 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:00,872 root INFO: Forward pass complete.
2025-12-02 18:28:00,886 __main__ INFO: ViT Epoch [3/50], Loss: 0.7252
2025-12-02 18:28:00,886 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:00,888 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:00,889 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,890 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,890 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:00,894 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:00,894 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,897 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,897 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:00,902 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:00,902 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:00,903 root INFO: Forward pass complete.
2025-12-02 18:28:00,919 __main__ INFO: ViT Epoch [4/50], Loss: 0.7391
2025-12-02 18:28:00,919 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:00,920 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:00,921 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,925 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,926 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:00,929 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:00,929 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,931 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,931 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:00,935 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:00,935 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:00,936 root INFO: Forward pass complete.
2025-12-02 18:28:00,949 __main__ INFO: ViT Epoch [5/50], Loss: 0.6725
2025-12-02 18:28:00,949 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:00,950 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:00,950 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,952 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,952 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:00,957 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:00,957 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,959 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,960 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:00,963 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:00,963 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:00,963 root INFO: Forward pass complete.
2025-12-02 18:28:00,972 __main__ INFO: ViT Epoch [6/50], Loss: 0.6952
2025-12-02 18:28:00,973 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:00,974 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:00,974 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,976 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,976 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:00,980 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:00,980 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,982 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,982 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:00,985 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:00,986 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:00,986 root INFO: Forward pass complete.
2025-12-02 18:28:00,996 __main__ INFO: ViT Epoch [7/50], Loss: 0.7118
2025-12-02 18:28:00,997 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:00,997 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:00,997 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:00,998 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:00,999 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,001 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,001 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,002 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,002 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,006 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,006 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,007 root INFO: Forward pass complete.
2025-12-02 18:28:01,014 __main__ INFO: ViT Epoch [8/50], Loss: 0.6690
2025-12-02 18:28:01,014 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,015 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,015 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,017 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,017 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,019 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,019 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,021 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,021 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,025 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,025 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,025 root INFO: Forward pass complete.
2025-12-02 18:28:01,032 __main__ INFO: ViT Epoch [9/50], Loss: 0.6824
2025-12-02 18:28:01,032 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,033 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,033 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,035 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,035 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,040 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,041 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,042 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,042 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,046 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,046 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,046 root INFO: Forward pass complete.
2025-12-02 18:28:01,056 __main__ INFO: ViT Epoch [10/50], Loss: 0.6561
2025-12-02 18:28:01,057 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,058 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,058 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,059 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,059 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,063 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,064 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,065 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,066 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,068 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,068 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,069 root INFO: Forward pass complete.
2025-12-02 18:28:01,078 __main__ INFO: ViT Epoch [11/50], Loss: 0.6660
2025-12-02 18:28:01,079 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,079 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,080 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,081 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,081 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,084 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,084 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,086 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,086 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,090 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,090 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,090 root INFO: Forward pass complete.
2025-12-02 18:28:01,097 __main__ INFO: ViT Epoch [12/50], Loss: 0.6565
2025-12-02 18:28:01,099 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,100 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,100 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,102 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,102 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,105 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,106 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,108 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,108 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,111 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,112 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,112 root INFO: Forward pass complete.
2025-12-02 18:28:01,119 __main__ INFO: ViT Epoch [13/50], Loss: 0.6475
2025-12-02 18:28:01,119 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,120 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,120 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,122 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,123 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,126 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,127 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,128 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,129 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,132 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,132 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,132 root INFO: Forward pass complete.
2025-12-02 18:28:01,142 __main__ INFO: ViT Epoch [14/50], Loss: 0.7059
2025-12-02 18:28:01,143 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,144 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,144 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,145 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,146 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,148 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,149 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,150 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,150 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,153 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,153 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,154 root INFO: Forward pass complete.
2025-12-02 18:28:01,163 __main__ INFO: ViT Epoch [15/50], Loss: 0.7133
2025-12-02 18:28:01,164 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,165 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,165 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,167 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,167 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,171 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,172 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,174 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,174 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,177 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,177 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,177 root INFO: Forward pass complete.
2025-12-02 18:28:01,187 __main__ INFO: ViT Epoch [16/50], Loss: 0.6694
2025-12-02 18:28:01,187 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,188 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,189 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,190 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,190 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,192 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,192 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,193 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,194 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,196 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,196 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,196 root INFO: Forward pass complete.
2025-12-02 18:28:01,207 __main__ INFO: ViT Epoch [17/50], Loss: 0.6485
2025-12-02 18:28:01,207 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,209 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,209 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,211 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,211 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,215 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,216 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,217 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,218 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,221 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,221 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,221 root INFO: Forward pass complete.
2025-12-02 18:28:01,231 __main__ INFO: ViT Epoch [18/50], Loss: 0.6386
2025-12-02 18:28:01,232 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,233 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,233 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,234 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,235 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,238 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,239 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,241 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,241 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,244 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,244 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,245 root INFO: Forward pass complete.
2025-12-02 18:28:01,252 __main__ INFO: ViT Epoch [19/50], Loss: 0.6374
2025-12-02 18:28:01,253 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,254 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,255 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,257 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,257 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,260 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,260 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,261 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,261 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,264 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,264 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,264 root INFO: Forward pass complete.
2025-12-02 18:28:01,274 __main__ INFO: ViT Epoch [20/50], Loss: 0.6301
2025-12-02 18:28:01,275 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,276 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,276 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,278 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,279 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,285 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,285 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,288 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,289 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,294 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,295 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,295 root INFO: Forward pass complete.
2025-12-02 18:28:01,304 __main__ INFO: ViT Epoch [21/50], Loss: 0.6171
2025-12-02 18:28:01,305 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,307 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,307 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,310 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,310 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,313 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,313 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,315 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,315 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,321 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,321 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,322 root INFO: Forward pass complete.
2025-12-02 18:28:01,331 __main__ INFO: ViT Epoch [22/50], Loss: 0.6090
2025-12-02 18:28:01,331 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,333 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,333 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,334 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,334 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,338 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,338 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,339 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,341 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,344 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,344 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,344 root INFO: Forward pass complete.
2025-12-02 18:28:01,352 __main__ INFO: ViT Epoch [23/50], Loss: 0.5859
2025-12-02 18:28:01,352 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,353 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,354 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,356 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,356 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,360 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,360 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,361 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,362 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,365 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,365 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,365 root INFO: Forward pass complete.
2025-12-02 18:28:01,374 __main__ INFO: ViT Epoch [24/50], Loss: 0.5369
2025-12-02 18:28:01,374 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,375 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,376 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,377 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,377 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,381 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,381 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,383 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,383 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,386 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,386 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,387 root INFO: Forward pass complete.
2025-12-02 18:28:01,396 __main__ INFO: ViT Epoch [25/50], Loss: 0.5053
2025-12-02 18:28:01,396 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,397 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,397 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,399 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,399 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,403 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,403 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,404 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,405 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,409 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,409 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,409 root INFO: Forward pass complete.
2025-12-02 18:28:01,417 __main__ INFO: ViT Epoch [26/50], Loss: 0.4920
2025-12-02 18:28:01,418 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,419 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,420 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,421 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,422 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,426 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,426 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,427 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,428 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,430 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,431 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,431 root INFO: Forward pass complete.
2025-12-02 18:28:01,440 __main__ INFO: ViT Epoch [27/50], Loss: 0.4050
2025-12-02 18:28:01,440 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,441 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,442 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,443 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,443 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,447 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,447 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,448 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,449 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,452 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,452 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,452 root INFO: Forward pass complete.
2025-12-02 18:28:01,461 __main__ INFO: ViT Epoch [28/50], Loss: 0.4109
2025-12-02 18:28:01,461 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,462 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,462 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,463 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,464 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,466 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,466 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,467 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,468 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,472 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,472 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,472 root INFO: Forward pass complete.
2025-12-02 18:28:01,481 __main__ INFO: ViT Epoch [29/50], Loss: 0.3742
2025-12-02 18:28:01,481 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,482 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,482 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,484 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,484 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,488 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,488 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,490 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,491 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,494 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,494 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,495 root INFO: Forward pass complete.
2025-12-02 18:28:01,503 __main__ INFO: ViT Epoch [30/50], Loss: 0.3460
2025-12-02 18:28:01,503 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,505 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,505 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,507 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,507 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,511 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,511 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,513 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,513 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,516 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,517 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,517 root INFO: Forward pass complete.
2025-12-02 18:28:01,526 __main__ INFO: ViT Epoch [31/50], Loss: 0.2816
2025-12-02 18:28:01,527 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,528 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,528 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,530 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,530 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,533 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,533 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,534 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,534 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,537 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,537 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,537 root INFO: Forward pass complete.
2025-12-02 18:28:01,546 __main__ INFO: ViT Epoch [32/50], Loss: 0.3424
2025-12-02 18:28:01,547 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,548 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,548 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,549 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,549 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,553 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,554 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,556 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,556 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,560 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,561 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,561 root INFO: Forward pass complete.
2025-12-02 18:28:01,569 __main__ INFO: ViT Epoch [33/50], Loss: 0.2206
2025-12-02 18:28:01,569 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,571 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,572 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,574 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,574 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,577 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,577 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,578 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,579 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,581 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,581 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,581 root INFO: Forward pass complete.
2025-12-02 18:28:01,591 __main__ INFO: ViT Epoch [34/50], Loss: 0.1900
2025-12-02 18:28:01,592 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,593 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,593 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,595 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,595 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,598 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,598 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,600 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,600 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,603 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,604 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,606 root INFO: Forward pass complete.
2025-12-02 18:28:01,615 __main__ INFO: ViT Epoch [35/50], Loss: 0.1755
2025-12-02 18:28:01,615 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,616 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,617 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,618 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,618 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,622 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,623 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,625 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,626 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,630 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,630 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,631 root INFO: Forward pass complete.
2025-12-02 18:28:01,639 __main__ INFO: ViT Epoch [36/50], Loss: 0.1078
2025-12-02 18:28:01,640 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,640 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,641 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,642 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,642 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,645 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,645 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,647 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,647 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,650 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,650 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,650 root INFO: Forward pass complete.
2025-12-02 18:28:01,661 __main__ INFO: ViT Epoch [37/50], Loss: 0.0742
2025-12-02 18:28:01,661 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,662 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,663 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,664 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,665 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,668 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,668 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,669 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,669 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,674 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,675 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,675 root INFO: Forward pass complete.
2025-12-02 18:28:01,684 __main__ INFO: ViT Epoch [38/50], Loss: 0.0389
2025-12-02 18:28:01,685 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,686 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,687 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,688 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,689 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,692 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,692 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,694 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,694 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,698 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,698 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,698 root INFO: Forward pass complete.
2025-12-02 18:28:01,708 __main__ INFO: ViT Epoch [39/50], Loss: 0.0358
2025-12-02 18:28:01,709 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,711 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,711 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,714 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,715 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,720 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,720 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,724 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,725 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,733 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,733 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,734 root INFO: Forward pass complete.
2025-12-02 18:28:01,749 __main__ INFO: ViT Epoch [40/50], Loss: 0.0166
2025-12-02 18:28:01,749 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,752 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,752 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,755 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,756 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,759 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,760 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,762 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,762 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,767 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,767 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,767 root INFO: Forward pass complete.
2025-12-02 18:28:01,782 __main__ INFO: ViT Epoch [41/50], Loss: 0.0247
2025-12-02 18:28:01,783 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,785 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,785 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,788 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,789 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,792 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,793 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,795 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,795 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,800 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,801 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,801 root INFO: Forward pass complete.
2025-12-02 18:28:01,812 __main__ INFO: ViT Epoch [42/50], Loss: 0.0111
2025-12-02 18:28:01,813 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,814 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,814 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,816 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,817 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,821 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,821 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,823 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,823 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,827 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,827 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,827 root INFO: Forward pass complete.
2025-12-02 18:28:01,835 __main__ INFO: ViT Epoch [43/50], Loss: 0.0110
2025-12-02 18:28:01,836 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,837 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,837 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,839 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,839 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,841 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,842 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,843 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,843 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,846 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,846 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,846 root INFO: Forward pass complete.
2025-12-02 18:28:01,853 __main__ INFO: ViT Epoch [44/50], Loss: 0.0070
2025-12-02 18:28:01,853 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,854 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,855 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,856 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,856 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,859 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,859 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,860 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,860 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,862 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,862 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,862 root INFO: Forward pass complete.
2025-12-02 18:28:01,872 __main__ INFO: ViT Epoch [45/50], Loss: 0.0058
2025-12-02 18:28:01,872 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,873 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,874 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,875 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,876 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,879 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,880 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,881 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,882 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,885 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,885 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,886 root INFO: Forward pass complete.
2025-12-02 18:28:01,895 __main__ INFO: ViT Epoch [46/50], Loss: 0.0063
2025-12-02 18:28:01,895 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,896 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,896 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,897 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,898 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,901 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,901 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,902 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,902 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,906 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,906 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,906 root INFO: Forward pass complete.
2025-12-02 18:28:01,914 __main__ INFO: ViT Epoch [47/50], Loss: 0.0053
2025-12-02 18:28:01,914 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,915 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,915 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,917 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,917 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,920 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,920 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,921 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,922 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,925 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,925 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,926 root INFO: Forward pass complete.
2025-12-02 18:28:01,935 __main__ INFO: ViT Epoch [48/50], Loss: 0.0057
2025-12-02 18:28:01,935 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,936 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,937 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,938 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,938 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,942 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,942 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,944 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,944 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,948 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,948 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,948 root INFO: Forward pass complete.
2025-12-02 18:28:01,958 __main__ INFO: ViT Epoch [49/50], Loss: 0.0041
2025-12-02 18:28:01,958 root INFO: Performing forward pass of Vision Transformer...
2025-12-02 18:28:01,959 root INFO: Performing forward pass of Transformer...
2025-12-02 18:28:01,959 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,960 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,961 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,964 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,965 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-02 18:28:01,966 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-02 18:28:01,966 root INFO: Performing forward pass of FeedForward...
2025-12-02 18:28:01,970 root INFO: Forward pass of FeedForward complete.
2025-12-02 18:28:01,970 root INFO: Forward pass of Transformer complete.
2025-12-02 18:28:01,971 root INFO: Forward pass complete.
2025-12-02 18:28:01,979 __main__ INFO: ViT Epoch [50/50], Loss: 0.0116
2025-12-02 18:28:01,982 __main__ INFO: Vision Transformer model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\vision_transformer_model.pth
2025-12-03 12:16:27,030 src INFO: Initialization of the src module and its submodules is complete.
2025-12-03 12:16:27,052 __main__ INFO: Training CNN model...
2025-12-03 12:16:27,052 __main__ INFO: Training CNN model...
2025-12-03 12:16:27,136 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-03 12:16:27,136 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-03 12:16:27,165 data_splitter_logger INFO: Data split: 16 train, 4 test
2025-12-03 12:16:27,165 __main__ WARNING: Could not reshape data; using dummy tensors for model smoke test
2025-12-03 12:16:27,165 __main__ WARNING: Could not reshape data; using dummy tensors for model smoke test
2025-12-03 12:16:31,205 __main__ INFO: CNN Epoch [1/50], Loss: 0.6544
2025-12-03 12:16:31,205 __main__ INFO: CNN Epoch [1/50], Loss: 0.6583
2025-12-03 12:16:31,842 __main__ INFO: CNN Epoch [2/50], Loss: 12.8477
2025-12-03 12:16:31,858 __main__ INFO: CNN Epoch [2/50], Loss: 12.7608
2025-12-03 12:16:32,375 __main__ INFO: CNN Epoch [3/50], Loss: 26.9811
2025-12-03 12:16:32,953 __main__ INFO: CNN Epoch [3/50], Loss: 17.5313
2025-12-03 12:16:33,730 __main__ INFO: CNN Epoch [4/50], Loss: 35.8127
2025-12-03 12:16:33,909 __main__ INFO: CNN Epoch [4/50], Loss: 16.3809
2025-12-03 12:16:34,252 __main__ INFO: CNN Epoch [5/50], Loss: 10.8607
2025-12-03 12:16:34,425 __main__ INFO: CNN Epoch [5/50], Loss: 21.9026
2025-12-03 12:16:34,721 __main__ INFO: CNN Epoch [6/50], Loss: 2.9421
2025-12-03 12:16:34,942 __main__ INFO: CNN Epoch [6/50], Loss: 15.7587
2025-12-03 12:16:35,424 __main__ INFO: CNN Epoch [7/50], Loss: 8.8858
2025-12-03 12:16:35,548 __main__ INFO: CNN Epoch [7/50], Loss: 17.8589
2025-12-03 12:16:35,902 __main__ INFO: CNN Epoch [8/50], Loss: 13.7284
2025-12-03 12:16:35,990 __main__ INFO: CNN Epoch [8/50], Loss: 15.0124
2025-12-03 12:16:36,404 __main__ INFO: CNN Epoch [9/50], Loss: 11.3123
2025-12-03 12:16:36,437 __main__ INFO: CNN Epoch [9/50], Loss: 3.1608
2025-12-03 12:16:36,736 __main__ INFO: CNN Epoch [10/50], Loss: 34.1404
2025-12-03 12:16:36,943 __main__ INFO: CNN Epoch [10/50], Loss: 2.8004
2025-12-03 12:16:37,158 __main__ INFO: CNN Epoch [11/50], Loss: 1.3916
2025-12-03 12:16:37,372 __main__ INFO: CNN Epoch [11/50], Loss: 9.9030
2025-12-03 12:16:37,556 __main__ INFO: CNN Epoch [12/50], Loss: 10.5670
2025-12-03 12:16:37,760 __main__ INFO: CNN Epoch [12/50], Loss: 12.8074
2025-12-03 12:16:37,964 __main__ INFO: CNN Epoch [13/50], Loss: 2.4765
2025-12-03 12:16:38,165 __main__ INFO: CNN Epoch [13/50], Loss: 2.6655
2025-12-03 12:16:38,473 __main__ INFO: CNN Epoch [14/50], Loss: 7.4422
2025-12-03 12:16:38,561 __main__ INFO: CNN Epoch [14/50], Loss: 0.0000
2025-12-03 12:16:38,963 __main__ INFO: CNN Epoch [15/50], Loss: 1.0944
2025-12-03 12:16:38,990 __main__ INFO: CNN Epoch [15/50], Loss: 5.5270
2025-12-03 12:16:39,405 __main__ INFO: CNN Epoch [16/50], Loss: 0.0000
2025-12-03 12:16:39,435 __main__ INFO: CNN Epoch [16/50], Loss: 7.4674
2025-12-03 12:16:39,846 __main__ INFO: CNN Epoch [17/50], Loss: 3.7142
2025-12-03 12:16:39,909 __main__ INFO: CNN Epoch [17/50], Loss: 0.3878
2025-12-03 12:16:40,343 __main__ INFO: CNN Epoch [18/50], Loss: 2.8081
2025-12-03 12:16:40,359 __main__ INFO: CNN Epoch [18/50], Loss: 4.7877
2025-12-03 12:16:40,735 __main__ INFO: CNN Epoch [19/50], Loss: 3.3788
2025-12-03 12:16:40,778 __main__ INFO: CNN Epoch [19/50], Loss: 7.0218
2025-12-03 12:16:41,116 __main__ INFO: CNN Epoch [20/50], Loss: 1.0644
2025-12-03 12:16:41,242 __main__ INFO: CNN Epoch [20/50], Loss: 0.0630
2025-12-03 12:16:41,546 __main__ INFO: CNN Epoch [21/50], Loss: 2.2558
2025-12-03 12:16:41,637 __main__ INFO: CNN Epoch [21/50], Loss: 1.8411
2025-12-03 12:16:41,951 __main__ INFO: CNN Epoch [22/50], Loss: 3.1389
2025-12-03 12:16:42,045 __main__ INFO: CNN Epoch [22/50], Loss: 0.0000
2025-12-03 12:16:42,391 __main__ INFO: CNN Epoch [23/50], Loss: 1.4174
2025-12-03 12:16:42,609 __main__ INFO: CNN Epoch [23/50], Loss: 0.0000
2025-12-03 12:16:42,813 __main__ INFO: CNN Epoch [24/50], Loss: 0.5293
2025-12-03 12:16:43,004 __main__ INFO: CNN Epoch [24/50], Loss: 0.0000
2025-12-03 12:16:43,280 __main__ INFO: CNN Epoch [25/50], Loss: 0.5182
2025-12-03 12:16:43,502 __main__ INFO: CNN Epoch [25/50], Loss: 0.0000
2025-12-03 12:16:43,716 __main__ INFO: CNN Epoch [26/50], Loss: 0.2958
2025-12-03 12:16:43,942 __main__ INFO: CNN Epoch [26/50], Loss: 10.6951
2025-12-03 12:16:44,160 __main__ INFO: CNN Epoch [27/50], Loss: 0.0000
2025-12-03 12:16:44,364 __main__ INFO: CNN Epoch [27/50], Loss: 1.1823
2025-12-03 12:16:44,560 __main__ INFO: CNN Epoch [28/50], Loss: 5.4268
2025-12-03 12:16:44,756 __main__ INFO: CNN Epoch [28/50], Loss: 0.0000
2025-12-03 12:16:44,960 __main__ INFO: CNN Epoch [29/50], Loss: 1.2395
2025-12-03 12:16:45,180 __main__ INFO: CNN Epoch [29/50], Loss: 0.0000
2025-12-03 12:16:45,384 __main__ INFO: CNN Epoch [30/50], Loss: 0.1302
2025-12-03 12:16:45,597 __main__ INFO: CNN Epoch [30/50], Loss: 0.0000
2025-12-03 12:16:45,794 __main__ INFO: CNN Epoch [31/50], Loss: 0.0000
2025-12-03 12:16:45,983 __main__ INFO: CNN Epoch [31/50], Loss: 0.0000
2025-12-03 12:16:46,255 __main__ INFO: CNN Epoch [32/50], Loss: 0.0000
2025-12-03 12:16:46,349 __main__ INFO: CNN Epoch [32/50], Loss: 0.2780
2025-12-03 12:16:46,693 __main__ INFO: CNN Epoch [33/50], Loss: 0.0000
2025-12-03 12:16:46,740 __main__ INFO: CNN Epoch [33/50], Loss: 0.0000
2025-12-03 12:16:47,163 __main__ INFO: CNN Epoch [34/50], Loss: 1.3832
2025-12-03 12:16:47,165 __main__ INFO: CNN Epoch [34/50], Loss: 1.1858
2025-12-03 12:16:47,520 __main__ INFO: CNN Epoch [35/50], Loss: 0.1199
2025-12-03 12:16:47,707 __main__ INFO: CNN Epoch [35/50], Loss: 0.0000
2025-12-03 12:16:47,995 __main__ INFO: CNN Epoch [36/50], Loss: 0.0000
2025-12-03 12:16:48,122 __main__ INFO: CNN Epoch [36/50], Loss: 0.0000
2025-12-03 12:16:48,368 __main__ INFO: CNN Epoch [37/50], Loss: 0.0000
2025-12-03 12:16:48,569 __main__ INFO: CNN Epoch [37/50], Loss: 0.0000
2025-12-03 12:16:48,831 __main__ INFO: CNN Epoch [38/50], Loss: 0.0000
2025-12-03 12:16:49,052 __main__ INFO: CNN Epoch [38/50], Loss: 0.0000
2025-12-03 12:16:49,253 __main__ INFO: CNN Epoch [39/50], Loss: 0.8821
2025-12-03 12:16:49,477 __main__ INFO: CNN Epoch [39/50], Loss: 0.0000
2025-12-03 12:16:49,719 __main__ INFO: CNN Epoch [40/50], Loss: 0.0000
2025-12-03 12:16:49,936 __main__ INFO: CNN Epoch [40/50], Loss: 0.0000
2025-12-03 12:16:50,162 __main__ INFO: CNN Epoch [41/50], Loss: 0.0000
2025-12-03 12:16:50,362 __main__ INFO: CNN Epoch [41/50], Loss: 0.0000
2025-12-03 12:16:50,600 __main__ INFO: CNN Epoch [42/50], Loss: 0.0000
2025-12-03 12:16:50,749 __main__ INFO: CNN Epoch [42/50], Loss: 0.0000
2025-12-03 12:16:51,070 __main__ INFO: CNN Epoch [43/50], Loss: 0.0000
2025-12-03 12:16:51,155 __main__ INFO: CNN Epoch [43/50], Loss: 0.0000
2025-12-03 12:16:51,503 __main__ INFO: CNN Epoch [44/50], Loss: 0.0000
2025-12-03 12:16:51,623 __main__ INFO: CNN Epoch [44/50], Loss: 0.0000
2025-12-03 12:16:51,874 __main__ INFO: CNN Epoch [45/50], Loss: 0.0000
2025-12-03 12:16:52,081 __main__ INFO: CNN Epoch [45/50], Loss: 0.0000
2025-12-03 12:16:52,319 __main__ INFO: CNN Epoch [46/50], Loss: 0.0000
2025-12-03 12:16:52,626 __main__ INFO: CNN Epoch [46/50], Loss: 0.0000
2025-12-03 12:16:52,750 __main__ INFO: CNN Epoch [47/50], Loss: 0.0000
2025-12-03 12:16:53,127 __main__ INFO: CNN Epoch [48/50], Loss: 0.0000
2025-12-03 12:16:53,127 __main__ INFO: CNN Epoch [47/50], Loss: 0.0000
2025-12-03 12:16:53,487 __main__ INFO: CNN Epoch [49/50], Loss: 0.0000
2025-12-03 12:16:53,634 __main__ INFO: CNN Epoch [48/50], Loss: 0.0000
2025-12-03 12:16:53,877 __main__ INFO: CNN Epoch [50/50], Loss: 0.0115
2025-12-03 12:16:54,059 __main__ INFO: CNN Epoch [49/50], Loss: 0.0000
2025-12-03 12:16:54,319 __main__ INFO: CNN Epoch [50/50], Loss: 0.0000
2025-12-03 12:16:55,737 __main__ INFO: CNN model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\cnn_model.pth
2025-12-03 12:16:55,737 __main__ INFO: CNN model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\cnn_model.pth
2025-12-03 12:16:55,816 __main__ INFO: Training Transformer model...
2025-12-03 12:16:55,816 __main__ INFO: Training Transformer model...
2025-12-03 12:16:55,906 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-03 12:16:55,906 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-03 12:16:55,906 __main__ WARNING: Data contains non-numeric values; using dummy data for smoke test
2025-12-03 12:16:55,921 __main__ WARNING: Data contains non-numeric values; using dummy data for smoke test
2025-12-03 12:16:55,921 transformer_model_logger INFO: Initializing Transformer model with input_dim=10, model_dim=512, num_heads=8, num_layers=6, output_dim=2, dropout=0.1.
2025-12-03 12:16:55,921 transformer_model_logger INFO: Initializing Transformer model with input_dim=10, model_dim=512, num_heads=8, num_layers=6, output_dim=2, dropout=0.1.
2025-12-03 12:16:55,921 positional_encoding_logger INFO: Initializing Positional Encoding with d_model=512, dropout=0.1, max_len=5000.
2025-12-03 12:16:55,921 positional_encoding_logger INFO: Initializing Positional Encoding with d_model=512, dropout=0.1, max_len=5000.
2025-12-03 12:16:56,549 positional_encoding_logger INFO: Positional Encoding initialized successfully.
2025-12-03 12:16:56,549 positional_encoding_logger INFO: Positional Encoding initialized successfully.
2025-12-03 12:16:56,722 transformer_model_logger INFO: Transformer model initialized successfully.
2025-12-03 12:16:56,722 transformer_model_logger INFO: Transformer model initialized successfully.
2025-12-03 12:16:56,722 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:16:56,722 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:16:56,738 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:16:56,738 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:16:56,764 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:16:56,764 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:16:57,860 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:16:57,865 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:16:58,771 __main__ INFO: Transformer Epoch [1/50], Loss: 0.7037
2025-12-03 12:16:58,771 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:16:58,771 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:16:58,771 __main__ INFO: Transformer Epoch [1/50], Loss: 0.6947
2025-12-03 12:16:58,771 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:16:58,771 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:16:58,771 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:16:58,786 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:16:59,288 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:16:59,304 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:16:59,961 __main__ INFO: Transformer Epoch [2/50], Loss: 7.0309
2025-12-03 12:16:59,979 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:16:59,979 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:16:59,990 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:00,007 __main__ INFO: Transformer Epoch [2/50], Loss: 6.5648
2025-12-03 12:17:00,023 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:00,023 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:00,023 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:00,523 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:00,542 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:01,273 __main__ INFO: Transformer Epoch [3/50], Loss: 1.3498
2025-12-03 12:17:01,289 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:01,289 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:01,305 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:01,320 __main__ INFO: Transformer Epoch [3/50], Loss: 0.6917
2025-12-03 12:17:01,336 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:01,336 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:01,336 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:01,871 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:01,899 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:02,629 __main__ INFO: Transformer Epoch [4/50], Loss: 3.3435
2025-12-03 12:17:02,645 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:02,645 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:02,658 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:02,688 __main__ INFO: Transformer Epoch [4/50], Loss: 3.8251
2025-12-03 12:17:02,704 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:02,704 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:02,704 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:03,329 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:03,361 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:04,182 __main__ INFO: Transformer Epoch [5/50], Loss: 2.1177
2025-12-03 12:17:04,189 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:04,189 __main__ INFO: Transformer Epoch [5/50], Loss: 0.8193
2025-12-03 12:17:04,189 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:04,189 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:04,189 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:04,198 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:04,198 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:04,757 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:04,788 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:05,506 __main__ INFO: Transformer Epoch [6/50], Loss: 2.3547
2025-12-03 12:17:05,510 __main__ INFO: Transformer Epoch [6/50], Loss: 0.9251
2025-12-03 12:17:05,510 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:05,510 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:05,519 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:05,519 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:05,523 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:05,526 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:06,030 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:06,061 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:06,695 __main__ INFO: Transformer Epoch [7/50], Loss: 1.3435
2025-12-03 12:17:06,711 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:06,711 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:06,726 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:06,726 __main__ INFO: Transformer Epoch [7/50], Loss: 0.8003
2025-12-03 12:17:06,726 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:06,726 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:06,742 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:07,315 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:07,315 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:08,068 __main__ INFO: Transformer Epoch [8/50], Loss: 0.6916
2025-12-03 12:17:08,080 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:08,080 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:08,085 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:08,100 __main__ INFO: Transformer Epoch [8/50], Loss: 0.7367
2025-12-03 12:17:08,100 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:08,100 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:08,117 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:08,606 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:08,638 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:09,405 __main__ INFO: Transformer Epoch [9/50], Loss: 0.9240
2025-12-03 12:17:09,420 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:09,420 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:09,420 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:09,452 __main__ INFO: Transformer Epoch [9/50], Loss: 0.8175
2025-12-03 12:17:09,452 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:09,452 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:09,452 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:09,988 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:09,988 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:10,670 __main__ INFO: Transformer Epoch [10/50], Loss: 0.9275
2025-12-03 12:17:10,686 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:10,686 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:10,686 __main__ INFO: Transformer Epoch [10/50], Loss: 0.7288
2025-12-03 12:17:10,686 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:10,686 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:10,686 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:10,701 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:11,230 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:11,905 __main__ INFO: Transformer Epoch [11/50], Loss: 0.6989
2025-12-03 12:17:11,905 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:11,905 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:11,920 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:11,920 __main__ INFO: Transformer Epoch [11/50], Loss: 0.7571
2025-12-03 12:17:11,936 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:11,936 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:11,936 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:12,454 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:12,489 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:13,316 __main__ INFO: Transformer Epoch [12/50], Loss: 0.7017
2025-12-03 12:17:13,316 __main__ INFO: Transformer Epoch [12/50], Loss: 0.7490
2025-12-03 12:17:13,316 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:13,316 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:13,316 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:13,316 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:13,332 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:13,332 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:13,911 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:13,958 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:14,628 __main__ INFO: Transformer Epoch [13/50], Loss: 0.7768
2025-12-03 12:17:14,644 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:14,644 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:14,660 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:14,691 __main__ INFO: Transformer Epoch [13/50], Loss: 0.7618
2025-12-03 12:17:14,691 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:14,691 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:14,707 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:15,253 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:15,347 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:15,917 __main__ INFO: Transformer Epoch [14/50], Loss: 0.8031
2025-12-03 12:17:15,933 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:15,933 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:15,949 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:16,036 __main__ INFO: Transformer Epoch [14/50], Loss: 0.7238
2025-12-03 12:17:16,036 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:16,050 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:16,050 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:16,486 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:16,577 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:17,096 __main__ INFO: Transformer Epoch [15/50], Loss: 0.7596
2025-12-03 12:17:17,112 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:17,112 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:17,127 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:17,206 __main__ INFO: Transformer Epoch [15/50], Loss: 0.6929
2025-12-03 12:17:17,206 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:17,206 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:17,206 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:17,659 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:17,738 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:18,253 __main__ INFO: Transformer Epoch [16/50], Loss: 0.7064
2025-12-03 12:17:18,269 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:18,269 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:18,285 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:18,363 __main__ INFO: Transformer Epoch [16/50], Loss: 0.6977
2025-12-03 12:17:18,363 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:18,363 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:18,378 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:18,816 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:18,899 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:19,564 __main__ INFO: Transformer Epoch [17/50], Loss: 0.6968
2025-12-03 12:17:19,580 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:19,580 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:19,596 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:19,667 __main__ INFO: Transformer Epoch [17/50], Loss: 0.7190
2025-12-03 12:17:19,683 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:19,683 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:19,683 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:20,152 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:20,244 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:20,779 __main__ INFO: Transformer Epoch [18/50], Loss: 0.7182
2025-12-03 12:17:20,794 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:20,794 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:20,810 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:20,905 __main__ INFO: Transformer Epoch [18/50], Loss: 0.7216
2025-12-03 12:17:20,905 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:20,905 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:20,937 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:21,404 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:21,532 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:22,064 __main__ INFO: Transformer Epoch [19/50], Loss: 0.7420
2025-12-03 12:17:22,064 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:22,064 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:22,080 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:22,206 __main__ INFO: Transformer Epoch [19/50], Loss: 0.7069
2025-12-03 12:17:22,206 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:22,206 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:22,223 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:22,634 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:22,760 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:23,314 __main__ INFO: Transformer Epoch [20/50], Loss: 0.7392
2025-12-03 12:17:23,314 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:23,314 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:23,334 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:23,448 __main__ INFO: Transformer Epoch [20/50], Loss: 0.6932
2025-12-03 12:17:23,464 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:23,464 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:23,464 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:23,905 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:24,027 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:24,541 __main__ INFO: Transformer Epoch [21/50], Loss: 0.7181
2025-12-03 12:17:24,541 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:24,557 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:24,557 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:24,699 __main__ INFO: Transformer Epoch [21/50], Loss: 0.6971
2025-12-03 12:17:24,699 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:24,699 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:24,706 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:25,153 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:25,294 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:25,941 __main__ INFO: Transformer Epoch [22/50], Loss: 0.7015
2025-12-03 12:17:25,955 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:25,955 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:25,970 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:26,090 __main__ INFO: Transformer Epoch [22/50], Loss: 0.7026
2025-12-03 12:17:26,093 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:26,096 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:26,096 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:26,531 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:26,664 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:27,246 __main__ INFO: Transformer Epoch [23/50], Loss: 0.6913
2025-12-03 12:17:27,265 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:27,265 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:27,265 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:27,419 __main__ INFO: Transformer Epoch [23/50], Loss: 0.7095
2025-12-03 12:17:27,419 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:27,419 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:27,419 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:27,841 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:27,985 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:28,439 __main__ INFO: Transformer Epoch [24/50], Loss: 0.6979
2025-12-03 12:17:28,455 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:28,455 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:28,455 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:28,612 __main__ INFO: Transformer Epoch [24/50], Loss: 0.7061
2025-12-03 12:17:28,612 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:28,612 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:28,631 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:29,014 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:29,166 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:29,605 __main__ INFO: Transformer Epoch [25/50], Loss: 0.7121
2025-12-03 12:17:29,613 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:29,613 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:29,621 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:29,778 __main__ INFO: Transformer Epoch [25/50], Loss: 0.6980
2025-12-03 12:17:29,778 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:29,778 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:29,792 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:30,154 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:30,293 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:30,753 __main__ INFO: Transformer Epoch [26/50], Loss: 0.7196
2025-12-03 12:17:30,758 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:30,759 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:30,763 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:30,921 __main__ INFO: Transformer Epoch [26/50], Loss: 0.6947
2025-12-03 12:17:30,921 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:30,921 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:30,936 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:31,327 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:31,529 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:32,014 __main__ INFO: Transformer Epoch [27/50], Loss: 0.7121
2025-12-03 12:17:32,021 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:32,021 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:32,030 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:32,316 __main__ INFO: Transformer Epoch [27/50], Loss: 0.6962
2025-12-03 12:17:32,316 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:32,316 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:32,327 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:32,654 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:32,898 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:33,460 __main__ INFO: Transformer Epoch [28/50], Loss: 0.7023
2025-12-03 12:17:33,479 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:33,480 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:33,492 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:33,697 __main__ INFO: Transformer Epoch [28/50], Loss: 0.6997
2025-12-03 12:17:33,697 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:33,697 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:33,715 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:34,102 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:34,275 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:34,763 __main__ INFO: Transformer Epoch [29/50], Loss: 0.6932
2025-12-03 12:17:34,763 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:34,763 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:34,794 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:35,108 __main__ INFO: Transformer Epoch [29/50], Loss: 0.7020
2025-12-03 12:17:35,120 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:35,120 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:35,124 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:35,407 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:35,684 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:35,994 __main__ INFO: Transformer Epoch [30/50], Loss: 0.6924
2025-12-03 12:17:36,002 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:36,002 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:36,011 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:36,294 __main__ INFO: Transformer Epoch [30/50], Loss: 0.7019
2025-12-03 12:17:36,294 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:36,294 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:36,310 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:36,558 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:36,856 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:37,147 __main__ INFO: Transformer Epoch [31/50], Loss: 0.7010
2025-12-03 12:17:37,147 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:37,147 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:37,162 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:37,524 __main__ INFO: Transformer Epoch [31/50], Loss: 0.6952
2025-12-03 12:17:37,532 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:37,532 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:37,540 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:37,802 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:38,149 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:38,444 __main__ INFO: Transformer Epoch [32/50], Loss: 0.7002
2025-12-03 12:17:38,459 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:38,459 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:38,459 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:38,758 __main__ INFO: Transformer Epoch [32/50], Loss: 0.6925
2025-12-03 12:17:38,758 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:38,758 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:38,773 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:39,057 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:39,432 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:39,767 __main__ INFO: Transformer Epoch [33/50], Loss: 0.7043
2025-12-03 12:17:39,767 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:39,767 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:39,777 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:40,088 __main__ INFO: Transformer Epoch [33/50], Loss: 0.6939
2025-12-03 12:17:40,104 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:40,104 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:40,104 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:40,371 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:40,659 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:40,937 __main__ INFO: Transformer Epoch [34/50], Loss: 0.7007
2025-12-03 12:17:40,937 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:40,937 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:40,952 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:41,246 __main__ INFO: Transformer Epoch [34/50], Loss: 0.6911
2025-12-03 12:17:41,246 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:41,246 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:41,262 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:41,509 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:41,793 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:42,097 __main__ INFO: Transformer Epoch [35/50], Loss: 0.6955
2025-12-03 12:17:42,111 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:42,111 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:42,130 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:42,533 __main__ INFO: Transformer Epoch [35/50], Loss: 0.6972
2025-12-03 12:17:42,533 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:42,533 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:42,546 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:42,750 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:43,161 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:43,556 __main__ INFO: Transformer Epoch [36/50], Loss: 0.6933
2025-12-03 12:17:43,564 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:43,564 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:43,588 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:44,147 __main__ INFO: Transformer Epoch [36/50], Loss: 0.6969
2025-12-03 12:17:44,154 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:44,155 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:44,162 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:44,301 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:44,844 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:45,001 __main__ INFO: Transformer Epoch [37/50], Loss: 0.6954
2025-12-03 12:17:45,010 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:45,010 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:45,021 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:45,534 __main__ INFO: Transformer Epoch [37/50], Loss: 0.6961
2025-12-03 12:17:45,541 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:45,543 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:45,549 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:45,695 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:46,204 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:46,314 __main__ INFO: Transformer Epoch [38/50], Loss: 0.6960
2025-12-03 12:17:46,329 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:46,329 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:46,336 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:46,804 __main__ INFO: Transformer Epoch [38/50], Loss: 0.6941
2025-12-03 12:17:46,804 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:46,804 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:46,820 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:46,946 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:47,407 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:47,544 __main__ INFO: Transformer Epoch [39/50], Loss: 0.6991
2025-12-03 12:17:47,549 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:47,549 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:47,559 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:48,039 __main__ INFO: Transformer Epoch [39/50], Loss: 0.6942
2025-12-03 12:17:48,042 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:48,042 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:48,049 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:48,192 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:48,648 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:48,766 __main__ INFO: Transformer Epoch [40/50], Loss: 0.6983
2025-12-03 12:17:48,776 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:48,776 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:48,782 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:49,242 __main__ INFO: Transformer Epoch [40/50], Loss: 0.6994
2025-12-03 12:17:49,242 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:49,242 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:49,256 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:49,381 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:49,906 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:50,048 __main__ INFO: Transformer Epoch [41/50], Loss: 0.6951
2025-12-03 12:17:50,056 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:50,056 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:50,060 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:50,529 __main__ INFO: Transformer Epoch [41/50], Loss: 0.6978
2025-12-03 12:17:50,542 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:50,542 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:50,556 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:50,726 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:51,161 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:51,492 __main__ INFO: Transformer Epoch [42/50], Loss: 0.6965
2025-12-03 12:17:51,492 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:51,492 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:51,509 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:51,876 __main__ INFO: Transformer Epoch [42/50], Loss: 0.6975
2025-12-03 12:17:51,876 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:51,889 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:51,891 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:52,147 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:52,544 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:52,774 __main__ INFO: Transformer Epoch [43/50], Loss: 0.6947
2025-12-03 12:17:52,790 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:52,790 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:52,806 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:53,163 __main__ INFO: Transformer Epoch [43/50], Loss: 0.6967
2025-12-03 12:17:53,163 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:53,179 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:53,179 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:53,414 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:53,742 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:54,130 __main__ INFO: Transformer Epoch [44/50], Loss: 0.6930
2025-12-03 12:17:54,143 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:54,144 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:54,154 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:54,440 __main__ INFO: Transformer Epoch [44/50], Loss: 0.6925
2025-12-03 12:17:54,440 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:54,440 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:54,457 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:54,757 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:55,110 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:55,380 __main__ INFO: Transformer Epoch [45/50], Loss: 0.6934
2025-12-03 12:17:55,388 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:55,389 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:55,392 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:55,761 __main__ INFO: Transformer Epoch [45/50], Loss: 0.6943
2025-12-03 12:17:55,773 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:55,773 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:55,779 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:56,055 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:56,462 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:56,823 __main__ INFO: Transformer Epoch [46/50], Loss: 0.6972
2025-12-03 12:17:56,825 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:56,825 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:56,842 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:57,136 __main__ INFO: Transformer Epoch [46/50], Loss: 0.6941
2025-12-03 12:17:57,140 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:57,140 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:57,149 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:57,450 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:57,757 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:58,179 __main__ INFO: Transformer Epoch [47/50], Loss: 0.6970
2025-12-03 12:17:58,179 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:58,179 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:58,195 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:58,455 __main__ INFO: Transformer Epoch [47/50], Loss: 0.6966
2025-12-03 12:17:58,455 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:58,455 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:58,470 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:58,781 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:59,098 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:17:59,420 __main__ INFO: Transformer Epoch [48/50], Loss: 0.6955
2025-12-03 12:17:59,423 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:59,423 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:59,442 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:17:59,759 __main__ INFO: Transformer Epoch [48/50], Loss: 0.6939
2025-12-03 12:17:59,763 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:17:59,763 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:17:59,771 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:18:00,090 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:18:00,527 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:18:00,964 __main__ INFO: Transformer Epoch [49/50], Loss: 0.6966
2025-12-03 12:18:00,973 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:18:00,973 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:18:00,986 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:18:01,275 __main__ INFO: Transformer Epoch [49/50], Loss: 0.6910
2025-12-03 12:18:01,275 transformer_model_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 10]).
2025-12-03 12:18:01,275 positional_encoding_logger INFO: Performing forward pass with input tensor of shape torch.Size([20, 512]).
2025-12-03 12:18:01,287 positional_encoding_logger INFO: Forward pass of Positional Encoding completed with output tensor of shape torch.Size([20, 20, 512]).
2025-12-03 12:18:01,556 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:18:01,880 transformer_model_logger INFO: Forward pass completed with output tensor of shape torch.Size([20, 2]).
2025-12-03 12:18:02,389 __main__ INFO: Transformer Epoch [50/50], Loss: 0.6910
2025-12-03 12:18:02,572 __main__ INFO: Transformer model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\transformer_model.pth
2025-12-03 12:18:02,587 __main__ INFO: Training SVM model...
2025-12-03 12:18:02,634 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-03 12:18:02,634 __main__ WARNING: Data contains non-numeric values; using dummy numeric data for SVM
2025-12-03 12:18:02,634 svm_model_logger INFO: Building SVM model with kernel=linear, C=1.0.
2025-12-03 12:18:02,634 svm_model_logger INFO: SVM model built successfully.
2025-12-03 12:18:02,666 __main__ INFO: Transformer Epoch [50/50], Loss: 0.6943
2025-12-03 12:18:02,790 __main__ INFO: SVM model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\svm_model.pkl
2025-12-03 12:18:02,790 __main__ INFO: Training Bayesian model...
2025-12-03 12:18:02,810 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-03 12:18:02,810 __main__ WARNING: Data contains non-numeric values; using dummy numeric data for Bayesian
2025-12-03 12:18:02,810 bayesian_model_logger INFO: Initialized BayesianModel with prior_mean=0, prior_std=1
2025-12-03 12:18:02,818 bayesian_model_logger INFO: Fitting Bayesian model...
2025-12-03 12:18:02,823 bayesian_model_logger INFO: Model fitted with classes: [0. 1.]
2025-12-03 12:18:02,825 __main__ INFO: Bayesian model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\bayesian_model.pkl
2025-12-03 12:18:02,825 __main__ INFO: Transformer model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\transformer_model.pth
2025-12-03 12:18:02,825 __main__ INFO: Training Vision Transformer model...
2025-12-03 12:18:02,838 __main__ INFO: Training SVM model...
2025-12-03 12:18:02,856 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-03 12:18:02,856 __main__ WARNING: Could not reshape data for ViT; using dummy tensors
2025-12-03 12:18:02,856 root INFO: Initializing Vision Transformer with img_size=8, patch_size=2, num_classes=2, dim=64, depth=2, heads=2, mlp_dim=256, dropout=0.1, emb_dropout=0.1
2025-12-03 12:18:02,871 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-03 12:18:02,871 __main__ WARNING: Data contains non-numeric values; using dummy numeric data for SVM
2025-12-03 12:18:02,871 svm_model_logger INFO: Building SVM model with kernel=linear, C=1.0.
2025-12-03 12:18:02,882 svm_model_logger INFO: SVM model built successfully.
2025-12-03 12:18:02,921 root INFO: Initializing Transformer with dim=64, depth=2, heads=2, mlp_dim=256, dropout=0.1
2025-12-03 12:18:02,921 root INFO: Initializing Multi-Head Attention with dim=64, heads=2, dropout=0.1
2025-12-03 12:18:02,921 root INFO: Initializing FeedForward with dim=64, hidden_dim=256, dropout=0.1
2025-12-03 12:18:02,929 __main__ INFO: SVM model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\svm_model.pkl
2025-12-03 12:18:02,929 root INFO: Initializing Multi-Head Attention with dim=64, heads=2, dropout=0.1
2025-12-03 12:18:02,929 __main__ INFO: Training Bayesian model...
2025-12-03 12:18:02,929 root INFO: Initializing FeedForward with dim=64, hidden_dim=256, dropout=0.1
2025-12-03 12:18:02,935 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:02,956 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-03 12:18:02,956 __main__ WARNING: Data contains non-numeric values; using dummy numeric data for Bayesian
2025-12-03 12:18:02,956 bayesian_model_logger INFO: Initialized BayesianModel with prior_mean=0, prior_std=1
2025-12-03 12:18:02,956 bayesian_model_logger INFO: Fitting Bayesian model...
2025-12-03 12:18:02,956 bayesian_model_logger INFO: Model fitted with classes: [0. 1.]
2025-12-03 12:18:02,985 __main__ INFO: Bayesian model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\bayesian_model.pkl
2025-12-03 12:18:02,985 __main__ INFO: Training Vision Transformer model...
2025-12-03 12:18:03,008 data_loader_logger INFO: Loaded data from F:\AMG-Project\Multimodel\src\..\data\processed\processed_data.csv with shape (20, 3)
2025-12-03 12:18:03,008 __main__ WARNING: Could not reshape data for ViT; using dummy tensors
2025-12-03 12:18:03,008 root INFO: Initializing Vision Transformer with img_size=8, patch_size=2, num_classes=2, dim=64, depth=2, heads=2, mlp_dim=256, dropout=0.1, emb_dropout=0.1
2025-12-03 12:18:03,008 root INFO: Initializing Transformer with dim=64, depth=2, heads=2, mlp_dim=256, dropout=0.1
2025-12-03 12:18:03,008 root INFO: Initializing Multi-Head Attention with dim=64, heads=2, dropout=0.1
2025-12-03 12:18:03,016 root INFO: Initializing FeedForward with dim=64, hidden_dim=256, dropout=0.1
2025-12-03 12:18:03,016 root INFO: Initializing Multi-Head Attention with dim=64, heads=2, dropout=0.1
2025-12-03 12:18:03,019 root INFO: Initializing FeedForward with dim=64, hidden_dim=256, dropout=0.1
2025-12-03 12:18:03,020 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:03,314 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,314 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,314 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,377 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,377 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,556 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,556 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,556 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,556 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,566 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,566 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,566 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,568 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,572 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,572 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,572 root INFO: Forward pass complete.
2025-12-03 12:18:03,572 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,572 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,574 root INFO: Forward pass complete.
2025-12-03 12:18:03,638 __main__ INFO: ViT Epoch [1/50], Loss: 0.7810
2025-12-03 12:18:03,638 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:03,638 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:03,638 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,638 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,638 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,638 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,638 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,638 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,656 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,657 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,657 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,657 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,657 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,657 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,657 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,657 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,671 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,671 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,671 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,671 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,671 root INFO: Forward pass complete.
2025-12-03 12:18:03,671 root INFO: Forward pass complete.
2025-12-03 12:18:03,690 __main__ INFO: ViT Epoch [2/50], Loss: 0.6668
2025-12-03 12:18:03,690 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:03,690 __main__ INFO: ViT Epoch [2/50], Loss: 0.7099
2025-12-03 12:18:03,690 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:03,698 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,698 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,698 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,698 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,701 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,701 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,704 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,704 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,704 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,704 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,704 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,704 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,704 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,704 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,714 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,714 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,714 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,714 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,718 root INFO: Forward pass complete.
2025-12-03 12:18:03,721 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,721 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,721 root INFO: Forward pass complete.
2025-12-03 12:18:03,738 __main__ INFO: ViT Epoch [3/50], Loss: 0.7360
2025-12-03 12:18:03,738 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:03,738 __main__ INFO: ViT Epoch [3/50], Loss: 0.7436
2025-12-03 12:18:03,738 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:03,738 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,738 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,738 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,738 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,738 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,738 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,738 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,738 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,751 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,755 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,757 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,757 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,757 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,757 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,757 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,757 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,757 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,768 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,768 root INFO: Forward pass complete.
2025-12-03 12:18:03,771 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,772 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,772 root INFO: Forward pass complete.
2025-12-03 12:18:03,801 __main__ INFO: ViT Epoch [4/50], Loss: 0.7071
2025-12-03 12:18:03,801 __main__ INFO: ViT Epoch [4/50], Loss: 0.7093
2025-12-03 12:18:03,801 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:03,804 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,804 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,804 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,804 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,804 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,804 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,817 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,817 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,817 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,821 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,821 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,821 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,821 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,821 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,821 root INFO: Forward pass complete.
2025-12-03 12:18:03,855 __main__ INFO: ViT Epoch [5/50], Loss: 0.6956
2025-12-03 12:18:03,856 __main__ INFO: ViT Epoch [5/50], Loss: 0.6757
2025-12-03 12:18:03,856 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:03,856 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:03,857 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,857 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,857 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,857 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,857 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,857 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,857 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,865 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,865 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,868 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,873 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,873 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,873 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,873 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,873 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,873 root INFO: Forward pass complete.
2025-12-03 12:18:03,886 __main__ INFO: ViT Epoch [6/50], Loss: 0.6748
2025-12-03 12:18:03,886 __main__ INFO: ViT Epoch [6/50], Loss: 0.6704
2025-12-03 12:18:03,886 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:03,901 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,901 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,901 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,901 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,901 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,901 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,909 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,909 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,909 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,909 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,909 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,909 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,919 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,919 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,919 root INFO: Forward pass complete.
2025-12-03 12:18:03,933 __main__ INFO: ViT Epoch [7/50], Loss: 0.7098
2025-12-03 12:18:03,933 __main__ INFO: ViT Epoch [7/50], Loss: 0.6930
2025-12-03 12:18:03,933 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:03,933 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:03,933 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,933 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,933 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,933 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,933 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,933 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,933 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,933 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,948 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,948 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,948 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,948 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,948 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,948 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,948 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,948 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,956 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,956 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,956 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:03,956 root INFO: Forward pass complete.
2025-12-03 12:18:03,965 __main__ INFO: ViT Epoch [8/50], Loss: 0.7094
2025-12-03 12:18:03,965 __main__ INFO: ViT Epoch [8/50], Loss: 0.6963
2025-12-03 12:18:03,965 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:03,981 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,981 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:03,981 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,983 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,983 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,985 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:03,988 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:03,988 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,988 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:03,988 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:03,988 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,002 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,002 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,002 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,002 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,002 root INFO: Forward pass complete.
2025-12-03 12:18:04,002 root INFO: Forward pass complete.
2025-12-03 12:18:04,018 __main__ INFO: ViT Epoch [9/50], Loss: 0.6792
2025-12-03 12:18:04,018 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,018 __main__ INFO: ViT Epoch [9/50], Loss: 0.7161
2025-12-03 12:18:04,018 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,018 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,018 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,018 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,018 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,028 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,028 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,028 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,028 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,028 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,028 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,028 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,028 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,028 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,028 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,028 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,028 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,044 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,044 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,044 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,044 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,044 root INFO: Forward pass complete.
2025-12-03 12:18:04,044 root INFO: Forward pass complete.
2025-12-03 12:18:04,057 __main__ INFO: ViT Epoch [10/50], Loss: 0.6934
2025-12-03 12:18:04,057 __main__ INFO: ViT Epoch [10/50], Loss: 0.7313
2025-12-03 12:18:04,057 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,057 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,060 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,060 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,060 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,060 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,060 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,060 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,060 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,060 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,060 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,060 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,060 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,060 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,060 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,076 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,076 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,076 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,076 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,076 root INFO: Forward pass complete.
2025-12-03 12:18:04,076 root INFO: Forward pass complete.
2025-12-03 12:18:04,091 __main__ INFO: ViT Epoch [11/50], Loss: 0.7217
2025-12-03 12:18:04,093 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,093 __main__ INFO: ViT Epoch [11/50], Loss: 0.6198
2025-12-03 12:18:04,093 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,093 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,095 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,095 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,095 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,097 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,097 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,097 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,097 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,104 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,104 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,104 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,104 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,104 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,104 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,104 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,104 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,104 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,104 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,104 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,104 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,104 root INFO: Forward pass complete.
2025-12-03 12:18:04,122 __main__ INFO: ViT Epoch [12/50], Loss: 0.6592
2025-12-03 12:18:04,122 __main__ INFO: ViT Epoch [12/50], Loss: 0.6646
2025-12-03 12:18:04,122 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,122 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,122 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,122 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,122 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,122 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,122 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,122 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,122 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,137 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,137 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,137 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,137 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,137 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,137 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,137 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,137 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,137 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,137 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,137 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,137 root INFO: Forward pass complete.
2025-12-03 12:18:04,137 root INFO: Forward pass complete.
2025-12-03 12:18:04,157 __main__ INFO: ViT Epoch [13/50], Loss: 0.6671
2025-12-03 12:18:04,157 __main__ INFO: ViT Epoch [13/50], Loss: 0.6479
2025-12-03 12:18:04,157 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,157 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,157 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,157 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,157 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,165 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,165 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,165 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,165 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,165 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,165 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,165 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,165 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,165 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,165 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,165 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,165 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,165 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,165 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,165 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,181 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,181 root INFO: Forward pass complete.
2025-12-03 12:18:04,181 root INFO: Forward pass complete.
2025-12-03 12:18:04,188 __main__ INFO: ViT Epoch [14/50], Loss: 0.6394
2025-12-03 12:18:04,188 __main__ INFO: ViT Epoch [14/50], Loss: 0.6149
2025-12-03 12:18:04,188 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,188 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,197 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,197 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,197 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,197 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,197 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,197 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,197 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,197 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,197 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,197 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,197 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,197 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,197 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,197 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,212 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,212 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,212 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,212 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,212 root INFO: Forward pass complete.
2025-12-03 12:18:04,228 __main__ INFO: ViT Epoch [15/50], Loss: 0.6067
2025-12-03 12:18:04,228 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,228 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,228 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,228 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,228 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,228 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,228 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,228 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,228 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,228 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,228 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,228 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,228 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,228 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,244 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,244 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,244 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,244 root INFO: Forward pass complete.
2025-12-03 12:18:04,244 root INFO: Forward pass complete.
2025-12-03 12:18:04,260 __main__ INFO: ViT Epoch [16/50], Loss: 0.6658
2025-12-03 12:18:04,260 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,260 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,260 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,260 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,260 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,260 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,260 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,260 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,260 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,260 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,260 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,275 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,275 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,275 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,275 root INFO: Forward pass complete.
2025-12-03 12:18:04,291 __main__ INFO: ViT Epoch [17/50], Loss: 0.6744
2025-12-03 12:18:04,291 __main__ INFO: ViT Epoch [17/50], Loss: 0.6115
2025-12-03 12:18:04,291 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,291 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,291 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,291 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,291 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,291 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,291 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,291 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,291 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,291 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,291 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,307 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,308 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,308 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,308 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,308 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,308 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,308 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,308 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,308 root INFO: Forward pass complete.
2025-12-03 12:18:04,323 __main__ INFO: ViT Epoch [18/50], Loss: 0.6160
2025-12-03 12:18:04,323 __main__ INFO: ViT Epoch [18/50], Loss: 0.6113
nsformer...
2025-12-03 12:18:04,323 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,323 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,323 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,323 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,323 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,323 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,323 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,323 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,323 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,338 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,338 root INFO: Forward pass of FeedForward complete.
ttention...
2025-12-03 12:18:04,338 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,338 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,338 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,338 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,338 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,338 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,338 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,338 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,338 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,338 root INFO: Forward pass complete.
2025-12-03 12:18:04,357 __main__ INFO: ViT Epoch [19/50], Loss: 0.5794
2025-12-03 12:18:04,357 __main__ INFO: ViT Epoch [19/50], Loss: 0.6386
2025-12-03 12:18:04,357 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,357 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,357 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,357 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,357 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,357 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,357 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,357 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,370 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,370 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,370 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,370 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,370 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,370 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,370 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,370 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,370 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,370 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,370 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,370 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,370 root INFO: Forward pass complete.
2025-12-03 12:18:04,386 __main__ INFO: ViT Epoch [20/50], Loss: 0.6255
2025-12-03 12:18:04,386 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,386 __main__ INFO: ViT Epoch [20/50], Loss: 0.6039
2025-12-03 12:18:04,386 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,386 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,386 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,401 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,401 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,401 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,401 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,401 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,401 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,401 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,401 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,401 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,401 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,401 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,401 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,401 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,401 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,417 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,417 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,417 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,417 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,417 root INFO: Forward pass complete.
2025-12-03 12:18:04,432 __main__ INFO: ViT Epoch [21/50], Loss: 0.5797
2025-12-03 12:18:04,432 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,432 __main__ INFO: ViT Epoch [21/50], Loss: 0.5546
2025-12-03 12:18:04,432 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,432 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,432 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,432 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,432 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,432 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,432 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,432 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,432 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,432 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,432 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,432 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,432 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,432 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,432 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,448 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,448 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,453 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,453 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,453 root INFO: Forward pass complete.
2025-12-03 12:18:04,457 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,457 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,457 root INFO: Forward pass complete.
2025-12-03 12:18:04,475 __main__ INFO: ViT Epoch [22/50], Loss: 0.5600
2025-12-03 12:18:04,475 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,475 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,475 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,475 __main__ INFO: ViT Epoch [22/50], Loss: 0.5700
2025-12-03 12:18:04,475 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,475 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,481 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,482 root INFO: Performing forward pass of FeedForward...
tion...
2025-12-03 12:18:04,489 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,489 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,489 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,489 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,497 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,497 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,497 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,497 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,506 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,507 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,507 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,507 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,507 root INFO: Forward pass complete.
2025-12-03 12:18:04,514 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,514 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,514 root INFO: Forward pass complete.
2025-12-03 12:18:04,530 __main__ INFO: ViT Epoch [23/50], Loss: 0.5482
2025-12-03 12:18:04,535 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,539 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,539 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,539 __main__ INFO: ViT Epoch [23/50], Loss: 0.4980
2025-12-03 12:18:04,539 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,542 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,543 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,543 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,544 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,544 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,544 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,544 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,544 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,555 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,555 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,555 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,555 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,559 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,560 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,561 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,561 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,561 root INFO: Forward pass complete.
2025-12-03 12:18:04,561 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,561 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,568 root INFO: Forward pass complete.
2025-12-03 12:18:04,589 __main__ INFO: ViT Epoch [24/50], Loss: 0.4797
2025-12-03 12:18:04,589 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,593 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,593 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,593 __main__ INFO: ViT Epoch [24/50], Loss: 0.4514
2025-12-03 12:18:04,593 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,597 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,597 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,597 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,597 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,601 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,601 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,605 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,605 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,607 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,607 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,607 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,609 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,609 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,609 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,609 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,609 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,609 root INFO: Forward pass complete.
2025-12-03 12:18:04,618 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,618 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,621 root INFO: Forward pass complete.
2025-12-03 12:18:04,635 __main__ INFO: ViT Epoch [25/50], Loss: 0.4353
2025-12-03 12:18:04,637 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,639 __main__ INFO: ViT Epoch [25/50], Loss: 0.4516
2025-12-03 12:18:04,639 root INFO: Performing forward pass of Transformer...
er...
2025-12-03 12:18:04,639 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,639 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,639 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,639 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,639 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,639 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,639 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,651 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,651 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,651 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,651 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,657 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,657 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,657 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,657 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,665 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,665 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,665 root INFO: Forward pass complete.
2025-12-03 12:18:04,665 root INFO: Forward pass complete.
2025-12-03 12:18:04,685 __main__ INFO: ViT Epoch [26/50], Loss: 0.3703
2025-12-03 12:18:04,687 __main__ INFO: ViT Epoch [26/50], Loss: 0.3821
2025-12-03 12:18:04,688 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,689 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,689 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,689 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,689 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,689 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,689 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,689 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,689 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,697 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,697 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,697 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,704 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,704 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,704 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,704 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,713 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,713 root INFO: Forward pass complete.
2025-12-03 12:18:04,713 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,713 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,713 root INFO: Forward pass complete.
2025-12-03 12:18:04,721 __main__ INFO: ViT Epoch [27/50], Loss: 0.3358
2025-12-03 12:18:04,734 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,738 __main__ INFO: ViT Epoch [27/50], Loss: 0.3218
2025-12-03 12:18:04,738 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,738 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,739 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,741 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,743 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,743 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,743 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,743 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,743 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,755 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,757 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,757 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,757 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,757 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,757 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,776 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,776 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,776 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,776 root INFO: Forward pass complete.
2025-12-03 12:18:04,776 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,776 root INFO: Forward pass complete.
2025-12-03 12:18:04,804 __main__ INFO: ViT Epoch [28/50], Loss: 0.2476
2025-12-03 12:18:04,804 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,804 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,804 __main__ INFO: ViT Epoch [28/50], Loss: 0.2662
2025-12-03 12:18:04,804 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,804 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,815 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,818 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,821 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,821 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,821 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,821 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,831 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,831 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,831 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,831 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,834 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,837 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,837 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,837 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,837 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,837 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,837 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,837 root INFO: Forward pass complete.
2025-12-03 12:18:04,837 root INFO: Forward pass complete.
2025-12-03 12:18:04,863 __main__ INFO: ViT Epoch [29/50], Loss: 0.2790
2025-12-03 12:18:04,863 __main__ INFO: ViT Epoch [29/50], Loss: 0.2001
2025-12-03 12:18:04,863 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,863 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,868 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,868 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,868 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,868 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,872 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,872 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,872 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,872 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,872 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,872 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,872 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,872 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,872 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,872 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,872 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,872 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,890 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,890 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,890 root INFO: Forward pass complete.
2025-12-03 12:18:04,890 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,890 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,893 root INFO: Forward pass complete.
2025-12-03 12:18:04,909 __main__ INFO: ViT Epoch [30/50], Loss: 0.2412
2025-12-03 12:18:04,909 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,909 __main__ INFO: ViT Epoch [30/50], Loss: 0.1735
2025-12-03 12:18:04,909 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,909 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,909 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,909 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,917 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,917 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,918 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,922 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,922 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,922 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,922 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,922 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,922 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,922 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,922 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,938 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,943 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,943 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,943 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,943 root INFO: Forward pass complete.
2025-12-03 12:18:04,951 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,951 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:04,954 root INFO: Forward pass complete.
2025-12-03 12:18:04,972 __main__ INFO: ViT Epoch [31/50], Loss: 0.1295
2025-12-03 12:18:04,972 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,972 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,972 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,972 __main__ INFO: ViT Epoch [31/50], Loss: 0.1785
2025-12-03 12:18:04,972 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:04,977 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:04,977 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,977 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,977 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,980 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,980 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,985 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,985 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,993 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:04,993 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:04,993 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:04,993 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:04,993 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,001 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,010 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,010 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,010 root INFO: Forward pass complete.
2025-12-03 12:18:05,023 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,023 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,023 root INFO: Forward pass complete.
2025-12-03 12:18:05,057 __main__ INFO: ViT Epoch [32/50], Loss: 0.0829
2025-12-03 12:18:05,058 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,058 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,058 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,058 __main__ INFO: ViT Epoch [32/50], Loss: 0.1346
2025-12-03 12:18:05,058 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,065 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,073 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,073 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,073 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,073 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,073 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,081 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,084 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,084 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,087 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,087 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,097 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,097 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,097 root INFO: Forward pass complete.
2025-12-03 12:18:05,121 __main__ INFO: ViT Epoch [33/50], Loss: 0.0720
2025-12-03 12:18:05,121 __main__ INFO: ViT Epoch [33/50], Loss: 0.0846
2025-12-03 12:18:05,121 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,121 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,121 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,121 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,121 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,121 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,121 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,134 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,137 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,137 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,137 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,137 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,137 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,137 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,137 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,137 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,137 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,154 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,154 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,154 root INFO: Forward pass complete.
2025-12-03 12:18:05,169 __main__ INFO: ViT Epoch [34/50], Loss: 0.0656
2025-12-03 12:18:05,169 __main__ INFO: ViT Epoch [34/50], Loss: 0.0792
2025-12-03 12:18:05,169 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,169 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,169 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,169 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,169 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,169 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,169 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,169 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,169 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,182 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,184 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,188 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,188 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,188 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,188 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,188 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,188 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,188 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,188 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,188 root INFO: Forward pass complete.
2025-12-03 12:18:05,188 root INFO: Forward pass complete.
2025-12-03 12:18:05,206 __main__ INFO: ViT Epoch [35/50], Loss: 0.0159
2025-12-03 12:18:05,206 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,206 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,206 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,206 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,206 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,206 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,206 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,206 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,206 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,222 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,223 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,223 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,223 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,223 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,223 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,223 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,223 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,223 root INFO: Forward pass complete.
2025-12-03 12:18:05,237 __main__ INFO: ViT Epoch [36/50], Loss: 0.0312
2025-12-03 12:18:05,237 __main__ INFO: ViT Epoch [36/50], Loss: 0.0112
2025-12-03 12:18:05,237 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,237 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,237 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,237 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,237 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,237 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,251 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,251 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,251 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,251 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,257 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,258 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,258 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,258 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,258 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,258 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,265 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,266 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,266 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,266 root INFO: Forward pass complete.
2025-12-03 12:18:05,266 root INFO: Forward pass complete.
2025-12-03 12:18:05,281 __main__ INFO: ViT Epoch [37/50], Loss: 0.0209
2025-12-03 12:18:05,281 __main__ INFO: ViT Epoch [37/50], Loss: 0.0133
2025-12-03 12:18:05,281 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,281 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,284 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,284 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,285 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,287 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,287 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,287 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,287 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,287 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,297 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,297 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,297 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,297 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,303 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,303 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,303 root INFO: Forward pass complete.
2025-12-03 12:18:05,303 root INFO: Forward pass complete.
2025-12-03 12:18:05,321 __main__ INFO: ViT Epoch [38/50], Loss: 0.0145
2025-12-03 12:18:05,321 __main__ INFO: ViT Epoch [38/50], Loss: 0.0125
2025-12-03 12:18:05,321 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,321 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,321 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,321 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,321 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,321 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,321 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,321 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,321 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,321 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,334 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,334 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,338 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,338 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,345 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,346 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,346 root INFO: Forward pass complete.
2025-12-03 12:18:05,367 __main__ INFO: ViT Epoch [39/50], Loss: 0.0099
2025-12-03 12:18:05,367 __main__ INFO: ViT Epoch [39/50], Loss: 0.0107
2025-12-03 12:18:05,368 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,372 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,372 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,372 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,372 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,372 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,372 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,372 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,379 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,379 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,379 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,384 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,387 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,392 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,392 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,392 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,392 root INFO: Forward pass complete.
2025-12-03 12:18:05,407 __main__ INFO: ViT Epoch [40/50], Loss: 0.0138
2025-12-03 12:18:05,407 __main__ INFO: ViT Epoch [40/50], Loss: 0.0115
2025-12-03 12:18:05,407 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,407 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,407 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,407 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,407 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,417 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,418 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,421 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,421 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,421 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,421 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,421 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,433 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,434 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,434 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,434 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,434 root INFO: Forward pass complete.
2025-12-03 12:18:05,449 __main__ INFO: ViT Epoch [41/50], Loss: 0.0112
2025-12-03 12:18:05,449 __main__ INFO: ViT Epoch [41/50], Loss: 0.0071
2025-12-03 12:18:05,449 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,449 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,453 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,453 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,453 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,453 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,453 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,453 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,453 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,453 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,458 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,458 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,458 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,458 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,458 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,468 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,468 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,468 root INFO: Forward pass complete.
2025-12-03 12:18:05,481 __main__ INFO: ViT Epoch [42/50], Loss: 0.0027
2025-12-03 12:18:05,481 __main__ INFO: ViT Epoch [42/50], Loss: 0.0095
2025-12-03 12:18:05,481 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,485 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,486 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,486 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,486 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,486 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,489 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,489 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,489 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,489 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,489 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,501 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,501 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,501 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,501 root INFO: Forward pass complete.
2025-12-03 12:18:05,517 __main__ INFO: ViT Epoch [43/50], Loss: 0.0022
2025-12-03 12:18:05,517 __main__ INFO: ViT Epoch [43/50], Loss: 0.0031
2025-12-03 12:18:05,518 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,520 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,520 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,520 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,522 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,522 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,522 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,522 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,530 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,530 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,530 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,534 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,534 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,534 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,534 root INFO: Forward pass complete.
2025-12-03 12:18:05,546 __main__ INFO: ViT Epoch [44/50], Loss: 0.0025
2025-12-03 12:18:05,546 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,546 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,546 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,546 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,546 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,546 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,558 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,558 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,558 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,558 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,562 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,562 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,562 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,562 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,562 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,562 root INFO: Forward pass complete.
2025-12-03 12:18:05,562 root INFO: Forward pass complete.
2025-12-03 12:18:05,578 __main__ INFO: ViT Epoch [45/50], Loss: 0.0025
2025-12-03 12:18:05,578 __main__ INFO: ViT Epoch [45/50], Loss: 0.0026
2025-12-03 12:18:05,578 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,578 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,578 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,578 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,578 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,578 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,578 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,578 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,578 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,578 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,578 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,578 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,593 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,593 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,593 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,593 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,593 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,593 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,593 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,593 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,593 root INFO: Forward pass complete.
2025-12-03 12:18:05,609 __main__ INFO: ViT Epoch [46/50], Loss: 0.0017
2025-12-03 12:18:05,609 __main__ INFO: ViT Epoch [46/50], Loss: 0.0019
2025-12-03 12:18:05,609 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,609 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,609 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,609 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,609 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,609 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,609 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,609 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,609 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,609 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,625 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,625 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,625 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,625 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,625 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,625 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,625 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,625 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,625 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,625 root INFO: Forward pass complete.
2025-12-03 12:18:05,644 __main__ INFO: ViT Epoch [47/50], Loss: 0.0019
2025-12-03 12:18:05,644 __main__ INFO: ViT Epoch [47/50], Loss: 0.0022
2025-12-03 12:18:05,644 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,644 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,651 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,651 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,651 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,654 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,654 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,655 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,659 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,659 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,659 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,659 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,659 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,659 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,664 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,664 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,670 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,670 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,670 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,670 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,670 root INFO: Forward pass complete.
2025-12-03 12:18:05,689 __main__ INFO: ViT Epoch [48/50], Loss: 0.0020
2025-12-03 12:18:05,689 __main__ INFO: ViT Epoch [48/50], Loss: 0.0017
2025-12-03 12:18:05,689 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,689 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,689 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,689 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,689 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,689 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,701 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,703 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,703 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,703 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,703 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,703 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,703 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,703 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,703 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,703 root INFO: Forward pass complete.
2025-12-03 12:18:05,703 root INFO: Forward pass complete.
2025-12-03 12:18:05,723 __main__ INFO: ViT Epoch [49/50], Loss: 0.0016
2025-12-03 12:18:05,723 __main__ INFO: ViT Epoch [49/50], Loss: 0.0021
2025-12-03 12:18:05,732 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,732 root INFO: Performing forward pass of Vision Transformer...
2025-12-03 12:18:05,732 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,732 root INFO: Performing forward pass of Transformer...
2025-12-03 12:18:05,732 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,738 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,738 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,738 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,738 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,738 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,738 root INFO: Performing forward pass of Multi-Head Attention...
2025-12-03 12:18:05,748 root INFO: Forward pass of Multi-Head Attention complete.
2025-12-03 12:18:05,748 root INFO: Performing forward pass of FeedForward...
2025-12-03 12:18:05,753 root INFO: Forward pass of FeedForward complete.
2025-12-03 12:18:05,753 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,753 root INFO: Forward pass of Transformer complete.
2025-12-03 12:18:05,753 root INFO: Forward pass complete.
2025-12-03 12:18:05,753 root INFO: Forward pass complete.
2025-12-03 12:18:05,772 __main__ INFO: ViT Epoch [50/50], Loss: 0.0093
2025-12-03 12:18:05,772 __main__ INFO: ViT Epoch [50/50], Loss: 0.0016
2025-12-03 12:18:05,780 __main__ INFO: Vision Transformer model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\vision_transformer_model.pth
2025-12-03 12:18:05,780 __main__ INFO: Vision Transformer model saved at F:\AMG-Project\Multimodel\src\..\models\saved_models\vision_transformer_model.pth
2025-12-03 12:19:04,264 src INFO: Initialization of the src module and its submodules is complete.
2025-12-03 12:19:04,265 evaluation_logger INFO: Evaluating CNN model...
2025-12-03 12:19:04,389 evaluation_logger WARNING: Could not load Keras model (TensorFlow not available). Skipping CNN evaluation.
2025-12-03 12:19:04,389 evaluation_logger INFO: Evaluating Transformer model...
2025-12-03 12:19:04,589 evaluation_logger ERROR: Error evaluating Transformer model: 'collections.OrderedDict' object has no attribute 'eval'
Traceback (most recent call last):
  File "F:\AMG-Project\Multimodel\src\evaluate.py", line 56, in evaluate_transformer
    model.eval()
    ^^^^^^^^^^
AttributeError: 'collections.OrderedDict' object has no attribute 'eval'
2025-12-03 12:19:04,615 evaluation_logger INFO: Evaluating SVM model...
2025-12-03 12:19:04,649 evaluation_logger ERROR: Error evaluating SVM model: 'charmap' codec can't decode byte 0x81 in position 44: character maps to <undefined>
Traceback (most recent call last):
  File "F:\AMG-Project\Multimodel\src\evaluate.py", line 82, in evaluate_svm
    model = read_from_file(model_path)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\src\utils\file_utils.py", line 64, in read_from_file
    return file.read()
           ^^^^^^^^^^^
  File "C:\Users\AKSHAY\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 44: character maps to <undefined>
2025-12-03 12:19:04,689 evaluation_logger INFO: Evaluating Bayesian model...
2025-12-03 12:19:04,705 evaluation_logger ERROR: Error evaluating Bayesian model: 'charmap' codec can't decode byte 0x81 in position 52: character maps to <undefined>
Traceback (most recent call last):
  File "F:\AMG-Project\Multimodel\src\evaluate.py", line 108, in evaluate_bayesian
    model = read_from_file(model_path)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\AMG-Project\Multimodel\src\utils\file_utils.py", line 64, in read_from_file
    return file.read()
           ^^^^^^^^^^^
  File "C:\Users\AKSHAY\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 52: character maps to <undefined>
2025-12-03 12:19:04,705 evaluation_logger INFO: Evaluating Vision Transformer model...
2025-12-03 12:19:04,705 root INFO: Initializing Vision Transformer with img_size=224, patch_size=16, num_classes=10, dim=768, depth=12, heads=12, mlp_dim=3072, dropout=0.1, emb_dropout=0.1
2025-12-03 12:19:04,719 root INFO: Initializing Transformer with dim=768, depth=12, heads=12, mlp_dim=3072, dropout=0.1
2025-12-03 12:19:04,719 root INFO: Initializing Multi-Head Attention with dim=768, heads=12, dropout=0.1
2025-12-03 12:19:04,738 root INFO: Initializing FeedForward with dim=768, hidden_dim=3072, dropout=0.1
2025-12-03 12:19:04,799 root INFO: Initializing Multi-Head Attention with dim=768, heads=12, dropout=0.1
2025-12-03 12:19:04,817 root INFO: Initializing FeedForward with dim=768, hidden_dim=3072, dropout=0.1
2025-12-03 12:19:04,851 root INFO: Initializing Multi-Head Attention with dim=768, heads=12, dropout=0.1
2025-12-03 12:19:04,867 root INFO: Initializing FeedForward with dim=768, hidden_dim=3072, dropout=0.1
2025-12-03 12:19:04,901 root INFO: Initializing Multi-Head Attention with dim=768, heads=12, dropout=0.1
2025-12-03 12:19:04,917 root INFO: Initializing FeedForward with dim=768, hidden_dim=3072, dropout=0.1
2025-12-03 12:19:04,956 root INFO: Initializing Multi-Head Attention with dim=768, heads=12, dropout=0.1
2025-12-03 12:19:04,973 root INFO: Initializing FeedForward with dim=768, hidden_dim=3072, dropout=0.1
2025-12-03 12:19:05,014 root INFO: Initializing Multi-Head Attention with dim=768, heads=12, dropout=0.1
2025-12-03 12:19:05,031 root INFO: Initializing FeedForward with dim=768, hidden_dim=3072, dropout=0.1
2025-12-03 12:19:05,073 root INFO: Initializing Multi-Head Attention with dim=768, heads=12, dropout=0.1
2025-12-03 12:19:05,099 root INFO: Initializing FeedForward with dim=768, hidden_dim=3072, dropout=0.1
2025-12-03 12:19:05,139 root INFO: Initializing Multi-Head Attention with dim=768, heads=12, dropout=0.1
2025-12-03 12:19:05,156 root INFO: Initializing FeedForward with dim=768, hidden_dim=3072, dropout=0.1
2025-12-03 12:19:05,189 root INFO: Initializing Multi-Head Attention with dim=768, heads=12, dropout=0.1
2025-12-03 12:19:05,216 root INFO: Initializing FeedForward with dim=768, hidden_dim=3072, dropout=0.1
2025-12-03 12:19:05,249 root INFO: Initializing Multi-Head Attention with dim=768, heads=12, dropout=0.1
2025-12-03 12:19:05,267 root INFO: Initializing FeedForward with dim=768, hidden_dim=3072, dropout=0.1
2025-12-03 12:19:05,306 root INFO: Initializing Multi-Head Attention with dim=768, heads=12, dropout=0.1
2025-12-03 12:19:05,322 root INFO: Initializing FeedForward with dim=768, hidden_dim=3072, dropout=0.1
2025-12-03 12:19:05,373 root INFO: Initializing Multi-Head Attention with dim=768, heads=12, dropout=0.1
2025-12-03 12:19:05,389 root INFO: Initializing FeedForward with dim=768, hidden_dim=3072, dropout=0.1
2025-12-03 12:19:05,450 evaluation_logger ERROR: Error evaluating Vision Transformer model: Error(s) in loading state_dict for VisionTransformer:
	Missing key(s) in state_dict: "transformer.layers.2.0.weight", "transformer.layers.2.0.bias", "transformer.layers.2.1.to_qkv.weight", "transformer.layers.2.1.to_out.0.weight", "transformer.layers.2.1.to_out.0.bias", "transformer.layers.2.2.weight", "transformer.layers.2.2.bias", "transformer.layers.2.3.net.0.weight", "transformer.layers.2.3.net.0.bias", "transformer.layers.2.3.net.3.weight", "transformer.layers.2.3.net.3.bias", "transformer.layers.3.0.weight", "transformer.layers.3.0.bias", "transformer.layers.3.1.to_qkv.weight", "transformer.layers.3.1.to_out.0.weight", "transformer.layers.3.1.to_out.0.bias", "transformer.layers.3.2.weight", "transformer.layers.3.2.bias", "transformer.layers.3.3.net.0.weight", "transformer.layers.3.3.net.0.bias", "transformer.layers.3.3.net.3.weight", "transformer.layers.3.3.net.3.bias", "transformer.layers.4.0.weight", "transformer.layers.4.0.bias", "transformer.layers.4.1.to_qkv.weight", "transformer.layers.4.1.to_out.0.weight", "transformer.layers.4.1.to_out.0.bias", "transformer.layers.4.2.weight", "transformer.layers.4.2.bias", "transformer.layers.4.3.net.0.weight", "transformer.layers.4.3.net.0.bias", "transformer.layers.4.3.net.3.weight", "transformer.layers.4.3.net.3.bias", "transformer.layers.5.0.weight", "transformer.layers.5.0.bias", "transformer.layers.5.1.to_qkv.weight", "transformer.layers.5.1.to_out.0.weight", "transformer.layers.5.1.to_out.0.bias", "transformer.layers.5.2.weight", "transformer.layers.5.2.bias", "transformer.layers.5.3.net.0.weight", "transformer.layers.5.3.net.0.bias", "transformer.layers.5.3.net.3.weight", "transformer.layers.5.3.net.3.bias", "transformer.layers.6.0.weight", "transformer.layers.6.0.bias", "transformer.layers.6.1.to_qkv.weight", "transformer.layers.6.1.to_out.0.weight", "transformer.layers.6.1.to_out.0.bias", "transformer.layers.6.2.weight", "transformer.layers.6.2.bias", "transformer.layers.6.3.net.0.weight", "transformer.layers.6.3.net.0.bias", "transformer.layers.6.3.net.3.weight", "transformer.layers.6.3.net.3.bias", "transformer.layers.7.0.weight", "transformer.layers.7.0.bias", "transformer.layers.7.1.to_qkv.weight", "transformer.layers.7.1.to_out.0.weight", "transformer.layers.7.1.to_out.0.bias", "transformer.layers.7.2.weight", "transformer.layers.7.2.bias", "transformer.layers.7.3.net.0.weight", "transformer.layers.7.3.net.0.bias", "transformer.layers.7.3.net.3.weight", "transformer.layers.7.3.net.3.bias", "transformer.layers.8.0.weight", "transformer.layers.8.0.bias", "transformer.layers.8.1.to_qkv.weight", "transformer.layers.8.1.to_out.0.weight", "transformer.layers.8.1.to_out.0.bias", "transformer.layers.8.2.weight", "transformer.layers.8.2.bias", "transformer.layers.8.3.net.0.weight", "transformer.layers.8.3.net.0.bias", "transformer.layers.8.3.net.3.weight", "transformer.layers.8.3.net.3.bias", "transformer.layers.9.0.weight", "transformer.layers.9.0.bias", "transformer.layers.9.1.to_qkv.weight", "transformer.layers.9.1.to_out.0.weight", "transformer.layers.9.1.to_out.0.bias", "transformer.layers.9.2.weight", "transformer.layers.9.2.bias", "transformer.layers.9.3.net.0.weight", "transformer.layers.9.3.net.0.bias", "transformer.layers.9.3.net.3.weight", "transformer.layers.9.3.net.3.bias", "transformer.layers.10.0.weight", "transformer.layers.10.0.bias", "transformer.layers.10.1.to_qkv.weight", "transformer.layers.10.1.to_out.0.weight", "transformer.layers.10.1.to_out.0.bias", "transformer.layers.10.2.weight", "transformer.layers.10.2.bias", "transformer.layers.10.3.net.0.weight", "transformer.layers.10.3.net.0.bias", "transformer.layers.10.3.net.3.weight", "transformer.layers.10.3.net.3.bias", "transformer.layers.11.0.weight", "transformer.layers.11.0.bias", "transformer.layers.11.1.to_qkv.weight", "transformer.layers.11.1.to_out.0.weight", "transformer.layers.11.1.to_out.0.bias", "transformer.layers.11.2.weight", "transformer.layers.11.2.bias", "transformer.layers.11.3.net.0.weight", "transformer.layers.11.3.net.0.bias", "transformer.layers.11.3.net.3.weight", "transformer.layers.11.3.net.3.bias". 
	size mismatch for pos_embedding: copying a param with shape torch.Size([1, 17, 64]) from checkpoint, the shape in current model is torch.Size([1, 197, 768]).
	size mismatch for cls_token: copying a param with shape torch.Size([1, 1, 64]) from checkpoint, the shape in current model is torch.Size([1, 1, 768]).
	size mismatch for patch_to_embedding.weight: copying a param with shape torch.Size([64, 12]) from checkpoint, the shape in current model is torch.Size([768, 768]).
	size mismatch for patch_to_embedding.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.0.0.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.0.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.0.1.to_qkv.weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([2304, 768]).
	size mismatch for transformer.layers.0.1.to_out.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([768, 768]).
	size mismatch for transformer.layers.0.1.to_out.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.0.2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.0.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.0.3.net.0.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([3072, 768]).
	size mismatch for transformer.layers.0.3.net.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([3072]).
	size mismatch for transformer.layers.0.3.net.3.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([768, 3072]).
	size mismatch for transformer.layers.0.3.net.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.1.0.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.1.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.1.1.to_qkv.weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([2304, 768]).
	size mismatch for transformer.layers.1.1.to_out.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([768, 768]).
	size mismatch for transformer.layers.1.1.to_out.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.1.2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.1.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.1.3.net.0.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([3072, 768]).
	size mismatch for transformer.layers.1.3.net.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([3072]).
	size mismatch for transformer.layers.1.3.net.3.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([768, 3072]).
	size mismatch for transformer.layers.1.3.net.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for mlp_head.0.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for mlp_head.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for mlp_head.1.weight: copying a param with shape torch.Size([2, 64]) from checkpoint, the shape in current model is torch.Size([10, 768]).
	size mismatch for mlp_head.1.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([10]).
Traceback (most recent call last):
  File "F:\AMG-Project\Multimodel\src\evaluate.py", line 138, in evaluate_vision_transformer
    model.load_state_dict(torch.load(model_path))
  File "F:\AMG-Project\Multimodel\.venv311\Lib\site-packages\torch\nn\modules\module.py", line 2629, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for VisionTransformer:
	Missing key(s) in state_dict: "transformer.layers.2.0.weight", "transformer.layers.2.0.bias", "transformer.layers.2.1.to_qkv.weight", "transformer.layers.2.1.to_out.0.weight", "transformer.layers.2.1.to_out.0.bias", "transformer.layers.2.2.weight", "transformer.layers.2.2.bias", "transformer.layers.2.3.net.0.weight", "transformer.layers.2.3.net.0.bias", "transformer.layers.2.3.net.3.weight", "transformer.layers.2.3.net.3.bias", "transformer.layers.3.0.weight", "transformer.layers.3.0.bias", "transformer.layers.3.1.to_qkv.weight", "transformer.layers.3.1.to_out.0.weight", "transformer.layers.3.1.to_out.0.bias", "transformer.layers.3.2.weight", "transformer.layers.3.2.bias", "transformer.layers.3.3.net.0.weight", "transformer.layers.3.3.net.0.bias", "transformer.layers.3.3.net.3.weight", "transformer.layers.3.3.net.3.bias", "transformer.layers.4.0.weight", "transformer.layers.4.0.bias", "transformer.layers.4.1.to_qkv.weight", "transformer.layers.4.1.to_out.0.weight", "transformer.layers.4.1.to_out.0.bias", "transformer.layers.4.2.weight", "transformer.layers.4.2.bias", "transformer.layers.4.3.net.0.weight", "transformer.layers.4.3.net.0.bias", "transformer.layers.4.3.net.3.weight", "transformer.layers.4.3.net.3.bias", "transformer.layers.5.0.weight", "transformer.layers.5.0.bias", "transformer.layers.5.1.to_qkv.weight", "transformer.layers.5.1.to_out.0.weight", "transformer.layers.5.1.to_out.0.bias", "transformer.layers.5.2.weight", "transformer.layers.5.2.bias", "transformer.layers.5.3.net.0.weight", "transformer.layers.5.3.net.0.bias", "transformer.layers.5.3.net.3.weight", "transformer.layers.5.3.net.3.bias", "transformer.layers.6.0.weight", "transformer.layers.6.0.bias", "transformer.layers.6.1.to_qkv.weight", "transformer.layers.6.1.to_out.0.weight", "transformer.layers.6.1.to_out.0.bias", "transformer.layers.6.2.weight", "transformer.layers.6.2.bias", "transformer.layers.6.3.net.0.weight", "transformer.layers.6.3.net.0.bias", "transformer.layers.6.3.net.3.weight", "transformer.layers.6.3.net.3.bias", "transformer.layers.7.0.weight", "transformer.layers.7.0.bias", "transformer.layers.7.1.to_qkv.weight", "transformer.layers.7.1.to_out.0.weight", "transformer.layers.7.1.to_out.0.bias", "transformer.layers.7.2.weight", "transformer.layers.7.2.bias", "transformer.layers.7.3.net.0.weight", "transformer.layers.7.3.net.0.bias", "transformer.layers.7.3.net.3.weight", "transformer.layers.7.3.net.3.bias", "transformer.layers.8.0.weight", "transformer.layers.8.0.bias", "transformer.layers.8.1.to_qkv.weight", "transformer.layers.8.1.to_out.0.weight", "transformer.layers.8.1.to_out.0.bias", "transformer.layers.8.2.weight", "transformer.layers.8.2.bias", "transformer.layers.8.3.net.0.weight", "transformer.layers.8.3.net.0.bias", "transformer.layers.8.3.net.3.weight", "transformer.layers.8.3.net.3.bias", "transformer.layers.9.0.weight", "transformer.layers.9.0.bias", "transformer.layers.9.1.to_qkv.weight", "transformer.layers.9.1.to_out.0.weight", "transformer.layers.9.1.to_out.0.bias", "transformer.layers.9.2.weight", "transformer.layers.9.2.bias", "transformer.layers.9.3.net.0.weight", "transformer.layers.9.3.net.0.bias", "transformer.layers.9.3.net.3.weight", "transformer.layers.9.3.net.3.bias", "transformer.layers.10.0.weight", "transformer.layers.10.0.bias", "transformer.layers.10.1.to_qkv.weight", "transformer.layers.10.1.to_out.0.weight", "transformer.layers.10.1.to_out.0.bias", "transformer.layers.10.2.weight", "transformer.layers.10.2.bias", "transformer.layers.10.3.net.0.weight", "transformer.layers.10.3.net.0.bias", "transformer.layers.10.3.net.3.weight", "transformer.layers.10.3.net.3.bias", "transformer.layers.11.0.weight", "transformer.layers.11.0.bias", "transformer.layers.11.1.to_qkv.weight", "transformer.layers.11.1.to_out.0.weight", "transformer.layers.11.1.to_out.0.bias", "transformer.layers.11.2.weight", "transformer.layers.11.2.bias", "transformer.layers.11.3.net.0.weight", "transformer.layers.11.3.net.0.bias", "transformer.layers.11.3.net.3.weight", "transformer.layers.11.3.net.3.bias". 
	size mismatch for pos_embedding: copying a param with shape torch.Size([1, 17, 64]) from checkpoint, the shape in current model is torch.Size([1, 197, 768]).
	size mismatch for cls_token: copying a param with shape torch.Size([1, 1, 64]) from checkpoint, the shape in current model is torch.Size([1, 1, 768]).
	size mismatch for patch_to_embedding.weight: copying a param with shape torch.Size([64, 12]) from checkpoint, the shape in current model is torch.Size([768, 768]).
	size mismatch for patch_to_embedding.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.0.0.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.0.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.0.1.to_qkv.weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([2304, 768]).
	size mismatch for transformer.layers.0.1.to_out.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([768, 768]).
	size mismatch for transformer.layers.0.1.to_out.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.0.2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.0.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.0.3.net.0.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([3072, 768]).
	size mismatch for transformer.layers.0.3.net.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([3072]).
	size mismatch for transformer.layers.0.3.net.3.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([768, 3072]).
	size mismatch for transformer.layers.0.3.net.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.1.0.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.1.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.1.1.to_qkv.weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([2304, 768]).
	size mismatch for transformer.layers.1.1.to_out.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([768, 768]).
	size mismatch for transformer.layers.1.1.to_out.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.1.2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.1.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for transformer.layers.1.3.net.0.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([3072, 768]).
	size mismatch for transformer.layers.1.3.net.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([3072]).
	size mismatch for transformer.layers.1.3.net.3.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([768, 3072]).
	size mismatch for transformer.layers.1.3.net.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for mlp_head.0.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for mlp_head.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for mlp_head.1.weight: copying a param with shape torch.Size([2, 64]) from checkpoint, the shape in current model is torch.Size([10, 768]).
	size mismatch for mlp_head.1.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([10]).
